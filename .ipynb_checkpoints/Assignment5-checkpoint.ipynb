{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. 클래스와 모듈의 공통점과 차이점에 대해 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공통점 : 하나의 독립된 이름 공간을 가진다.\n",
    "\n",
    "차이점 : 모듈은 파일 단위로 이름 공간 구성, 클래스는 클래스 영역으로 이름 공간 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다형성에 대해 설명하고 다형성을 보여주는 자신만의 파이썬 코드 예제를 제시하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다형성이란 같은 코드이지만 상황에 따라 다른 로직을 수행하는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멍멍\n",
      "야옹\n"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    def bark(self):\n",
    "        pass\n",
    "\n",
    "class Dog(Animal):\n",
    "    def bark(self):\n",
    "        print \"멍멍\"\n",
    "\n",
    "class Cat(Animal):\n",
    "    def bark(self):\n",
    "        print \"야옹\"\n",
    "        \n",
    "class Fish(Animal):\n",
    "    pass\n",
    "\n",
    "animals = [Dog(), Cat(), Fish()]\n",
    "for animal in animals:\n",
    "    animal.bark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다음 각 요구사항 모두를 만족시키는 Counter 클래스를 코딩하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 1. 생성자에 count 값과 step 값을 인자로 받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1\n",
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "c = Count(10)\n",
    "print c.count\n",
    "print c.step\n",
    "d = Count(10, 2)\n",
    "print d.count\n",
    "print d.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 2. 다음과 같이 Counter의 인스턴스를 출력을 해주는 __str__() 메소드를 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count(step: 1 )] 10\n",
      "[Count(step: 2 )] 10\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "    def __str__(self):\n",
    "        return \"[Count(step: \" + str(self.step) + \" )] \" + str(self.count)\n",
    "c = Count(10)\n",
    "print c\n",
    "d = Count(10, 2)\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 3. 다음과 같이 step에 주어진 증분만큼 count를 증가시키는 incr() 메소드를 Counter 클래스 내에 구현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count(step: 1 )] 10\n",
      "[Count(step: 1 )] 11\n",
      "[Count(step: 2 )] 10\n",
      "[Count(step: 2 )] 12\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "    def __str__(self):\n",
    "        return \"[Count(step: \" + str(self.step) + \" )] \" + str(self.count)\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "c = Count(10)\n",
    "print c\n",
    "c.incr()\n",
    "print c\n",
    "d = Count(10, 2)\n",
    "print d\n",
    "d.incr()\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 4. Counter 클래스 내에 관련 메소드를 추가하여 인스턴스 객체를 직접 호출(call)할 수 있도록 하시오. 인스턴스 객체를 직접 호출했을 때에 내부적으로 incr() 메소드를 호출하는 방법으로 구현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count(step: 1 )] 10\n",
      "[Count(step: 1 )] 11\n",
      "[Count(step: 2 )] 10\n",
      "[Count(step: 2 )] 12\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "    def __str__(self):\n",
    "        return \"[Count(step: \" + str(self.step) + \" )] \" + str(self.count)\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "    def __call__(self):\n",
    "        self.incr()\n",
    "c = Count(10)\n",
    "print c\n",
    "c()\n",
    "print c\n",
    "d = Count(10, 2)\n",
    "print d\n",
    "d()\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 5. 다음과 같은 두 개의 산술 연산 (+, -)이 수행될 수 있도록 Counter 클래스 내에 관련 메소드를 추가하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count(step: 1 )] 10\n",
      "[Count(step: 1 )] 15\n",
      "[Count(step: 2 )] 10\n",
      "[Count(step: 2 )] 5\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "    def __str__(self):\n",
    "        return \"[Count(step: \" + str(self.step) + \" )] \" + str(self.count)\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "    def __call__(self):\n",
    "        self.incr()\n",
    "    def __add__(self, value):\n",
    "        self.count += value\n",
    "        return self\n",
    "    def __sub__(self, value):\n",
    "        self.count -= value\n",
    "        return self\n",
    "c = Count(10)\n",
    "print c\n",
    "c = c + 5\n",
    "print c\n",
    "d = Count(10, 2)\n",
    "print d\n",
    "d = d - 5\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 6. 다음과 같은 관계연산 (>, <, ==)이 수행될 수 있도록 Counter 클래스 내에 관련 메소드를 추가하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "class Count:\n",
    "    def __init__(self, *args):\n",
    "        self.count = args[0]\n",
    "        self.step = 1\n",
    "        if len(args) > 1:\n",
    "            self.step = args[1]\n",
    "    def __str__(self):\n",
    "        return \"[Count(step: \" + str(self.step) + \" )] \" + str(self.count)\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "    def __call__(self):\n",
    "        self.incr()\n",
    "    def __add__(self, value):\n",
    "        self.count += value\n",
    "        return self\n",
    "    def __sub__(self, value):\n",
    "        self.count -= value\n",
    "        return self\n",
    "    def __lt__(self, value):\n",
    "        return self.count < value\n",
    "    def __eq__(self, value):\n",
    "        return self.count == value\n",
    "    def __ne__(self, value):\n",
    "        return self.count != value\n",
    "    def __gt__(self, value):\n",
    "        return self.count > value\n",
    "\n",
    "c = Count(10)\n",
    "d = Count(10, 2)\n",
    "print c > 10\n",
    "print d > 10\n",
    "print c < 10\n",
    "print d < 10\n",
    "print c == 17\n",
    "print d != 9       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 다음 클래스 정의에서 __init__(), __str()__(), elimicate_duplicate()의 세 개의 메소드 코드 내용을 자신이 다른 사람에게 가르친다고 생각하며 설명해보시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3}\n",
      "MySet: {2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    print s\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init 함수는 클래스의 생성자 함수입니다.\n",
    "\n",
    "클래스가 처음 생성될 때, 처음 인스턴스가 할당될 때, 호출 됩니다. \n",
    "\n",
    "(self, l) <-- \n",
    "\n",
    "이부분을 보면 이 클래스는 생성자의 매개변수로 한개의 값이 요구됨을 알 수 있습니다.\n",
    "\n",
    "s = MySet([1, 2, 2, 3]) \n",
    "\n",
    "이 코드에서 init 함수가 호출되고, 매개변수로 l = [1, 2, 2, 3] 이 전달됩니다.\n",
    "\n",
    "for e in l \n",
    "\n",
    "이 부분에서 매개변수로 넘어온 [1, 2, 2, 3] 의 각 원소를 차례로 꺼내서 \n",
    "\n",
    "self.append(e)\n",
    "\n",
    "를 하는데 이 클래스는 list 클래스를 상속받아 구현되었기 때문에 부모의 함수인\n",
    "\n",
    "append를 사용할 수 있습니다. 이를 자신의 원소에 매개변수의 원소를 추가합니다.\n",
    "\n",
    "모두 추가하면, 마지막으로 eliminate_duplicate를 호출하여 중복 원소를 제거합니다.\n",
    "\n",
    "str 함수는 문자열을 반환해주는 함수입니다.\n",
    "\n",
    "print 와 함께 스면 강제로 호출되어 출력을 할 수 있도록 해줍니다.\n",
    "\n",
    "여기서 구현된 str 함수의 경우 \"MySet: {\" 을 시작으로 모든 원소를 모두 이어 붙이고 마지막에\n",
    "\n",
    "\"}\" 로 마무리하는 문자열을 반환해줍니다.\n",
    "\n",
    "eliminate_duplicate 는 특이하게요 상단에 @staticmethod가 있습니다.\n",
    "\n",
    "정적 함수의 의미입니다. \n",
    "\n",
    "이는 인스턴스화를 하지 않아도 클래스 자체로도 함수를 사용할 수 있습니다.\n",
    "\n",
    "함수의 기능은 매개변수로 넘겨 받은 리스트의 원소를 하나씩 탐색합니다.\n",
    "\n",
    "빈 리스트를 준비하고, 하나씩 이어 붙이되, 이미 넣은 원소는 또다시 넣지 않습니다.\n",
    "\n",
    "이렇게 하면 중복이 제거된 리스트가 생성됩니다.\n",
    "\n",
    "매개변수로 넘겨받은 리스트에 중복이 제거된 리스트의 값을 복사합니다.\n",
    "\n",
    "결국 매개변수로 넘겨받은 리스트는 원소의 중복이 제거된 리스트로 변합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 4번 문제에 정의된 MySet 클래스에 메소드를 추가하여 다음 각 요구사항 모두를 만족시키는 코딩을 제시하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요구사항 1. | 연산으로 두 집합의 합집합을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "            \n",
    "    def __or__(self, other):\n",
    "        res = MySet([])\n",
    "        for e in self:\n",
    "            res.append(e)\n",
    "        for e in other:\n",
    "            res.append(e)\n",
    "        MySet.eliminate_duplicate(res)\n",
    "        return res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    u = s | t\n",
    "    print u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {2 ,3}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "            \n",
    "    def __or__(self, other):\n",
    "        for e in other:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "        return self\n",
    "    \n",
    "    def __and__(self, other):\n",
    "        res = MySet([])\n",
    "        for e in self:\n",
    "            if e in other:\n",
    "                res.append(e)\n",
    "        return res\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    u = s & t\n",
    "    print u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "            \n",
    "    def __or__(self, other):\n",
    "        for e in other:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "        return self\n",
    "    \n",
    "    def __and__(self, other):\n",
    "        res = MySet([])\n",
    "        for e in self:\n",
    "            if e in other:\n",
    "                res.append(e)\n",
    "        return res\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        res = MySet([])\n",
    "        for e in self:\n",
    "            if e not in other:\n",
    "                res.append(e)\n",
    "        return res\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 3])\n",
    "    t = MySet([3, 4, 5])\n",
    "    u = s - t\n",
    "    print u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 다음 예제 내에 있는 len(), bool() 내장함수와 in 키워드 사용 예제가 별다른 메소드 정의를 하지 않았는 데도 올바르게 수행되는 이유를 설명하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "s = MySet([1, 2, 3, 4, 5, 6])\n",
    "print len(s)\n",
    "print bool(s)\n",
    "print 2 in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__delslice__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getslice__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setslice__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySet 은 list를 상속 받고 있다. 굳이 정의하지 않아도 \n",
    "\n",
    "부모의 클래스에 정의된 함수와 변수를 사용할 수 있다.\n",
    "\n",
    "\\_\\_len\\_\\_, 이 존재하므로, len 함수를 사용할 수 있고\n",
    "\n",
    "\\_\\_contains\\_\\_, 가 존재하므로, in 표현을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7.  오일러 문제 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366\n"
     ]
    }
   ],
   "source": [
    "num = 2 ** 1000\n",
    "str_num = str(num)\n",
    "sum_num = 0\n",
    "for s in str_num:\n",
    "    sum_num += int(s)\n",
    "print sum_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 오일러 문제 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21124\n"
     ]
    }
   ],
   "source": [
    "one_to_nine = [\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"four\",\n",
    "    \"five\",\n",
    "    \"six\",\n",
    "    \"seven\",\n",
    "    \"eight\",\n",
    "    \"nine\",\n",
    "]\n",
    "ten_to_nineteen = [\n",
    "    \"ten\",\n",
    "    \"eleven\",\n",
    "    \"twelve\",\n",
    "    \"thirteen\",\n",
    "    \"fourteen\",\n",
    "    \"fifteen\",\n",
    "    \"sixteen\",\n",
    "    \"seventeen\",\n",
    "    \"eighteen\",\n",
    "    \"nineteen\",\n",
    "]\n",
    "twenty_to_ninety = [\n",
    "    \"twenty\",\n",
    "    \"thirty\",\n",
    "    \"forty\",\n",
    "    \"fifty\",\n",
    "    \"sixty\",\n",
    "    \"seventy\",\n",
    "    \"eighty\",\n",
    "    \"ninety\",\n",
    "]\n",
    "sum_of_1_9 = 0\n",
    "for s in one_to_nine:\n",
    "    sum_of_1_9 += len(s)\n",
    "sum_of_10_19 = 0\n",
    "for s in ten_to_nineteen:\n",
    "    sum_of_10_19 += len(s)\n",
    "sum_of_20_99 = 0\n",
    "for s in twenty_to_ninety:\n",
    "    add = len(s) * 10 + sum_of_1_9\n",
    "    sum_of_20_99 += add\n",
    "sum_of_1_99 = sum_of_1_9 + sum_of_10_19 + sum_of_20_99\n",
    "sum_of_100_999 = 0\n",
    "for s in one_to_nine:\n",
    "    add = (len(s) + len(\"hundred\")) * 100\n",
    "    add += len(\"and\") * 99\n",
    "    add += sum_of_1_99\n",
    "    sum_of_100_999 += add\n",
    "sum_of_1_1000 = sum_of_1_99 + sum_of_100_999 + len(\"one\") + len(\"thousand\")\n",
    "print sum_of_1_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9. 오일러 문제 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75], [170, 139], [187, 217, 221], [205, 252, 308, 231], [225, 256, 390, 355, 296], [244, 257, 413, 465, 358, 330], [332, 259, 490, 538, 472, 421, 397], [431, 397, 494, 566, 544, 488, 491, 489], [472, 472, 520, 622, 649, 584, 571, 561, 522], [513, 520, 592, 655, 696, 681, 621, 587, 655, 551], [566, 591, 636, 720, 721, 739, 772, 673, 752, 706, 565], [636, 602, 669, 748, 798, 812, 789, 850, 791, 820, 723, 622], [727, 707, 721, 786, 815, 826, 903, 893, 908, 870, 847, 752, 670], [790, 793, 725, 854, 904, 879, 970, 933, 981, 924, 939, 934, 792, 701], [794, 855, 891, 881, 927, 913, 1040, 1068, 1054, 1074, 977, 992, 994, 796, 724]]\n"
     ]
    }
   ],
   "source": [
    "li = '''75\n",
    "95 64\n",
    "17 47 82\n",
    "18 35 87 10\n",
    "20 04 82 47 65\n",
    "19 01 23 75 03 34\n",
    "88 02 77 73 07 63 67\n",
    "99 65 04 28 06 16 70 92\n",
    "41 41 26 56 83 40 80 70 33\n",
    "41 48 72 33 47 32 37 16 94 29\n",
    "53 71 44 65 25 43 91 52 97 51 14\n",
    "70 11 33 28 77 73 17 78 39 68 17 57\n",
    "91 71 52 38 17 14 91 43 58 50 27 29 48\n",
    "63 66 04 68 89 53 67 30 73 16 69 87 40 31\n",
    "04 62 98 27 23 09 70 98 73 93 38 53 60 04 23'''\n",
    "\n",
    "arrs = []\n",
    "li = li.split('\\n')\n",
    "for line in li:\n",
    "    new_arr = []\n",
    "    line = line.split()\n",
    "    for num in line:\n",
    "        new_arr.append(int(num))\n",
    "    arrs.append(new_arr)\n",
    "\n",
    "for row in range(0,len(arrs)):\n",
    "    for col in range(0, len(arrs[row])):\n",
    "        if row >= 1:\n",
    "            cur = 0\n",
    "            if col < len(arrs[row-1]):\n",
    "                cur = arrs[row-1][col]\n",
    "            before = 0\n",
    "            if col >= 1:\n",
    "                before = arrs[row-1][col-1]\n",
    "            arrs[row][col] += max(cur, before)\n",
    "print arrs           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 오일러 문제 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "def isYoon(year):\n",
    "    return (year % 4 == 0 and year % 100 != 0 or year % 400 == 0);\n",
    "\n",
    "month = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "year = 1900\n",
    "day_from_zero = 1\n",
    "sun_cnt = 0\n",
    "while year < 2001:\n",
    "    month[1] = 28\n",
    "    if isYoon(year):\n",
    "        month[1] = 29\n",
    "    for day in month:\n",
    "        if year > 1900 and day_from_zero % 7 == 0:\n",
    "            sun_cnt += 1\n",
    "        day_from_zero += day\n",
    "    year += 1\n",
    "print sun_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###11. 오일러 문제 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "def factorial(num):\n",
    "    mul_sum = 1\n",
    "    while num > 1:\n",
    "        mul_sum *= num\n",
    "        num -= 1\n",
    "    return mul_sum\n",
    "\n",
    "str_fac = str(factorial(100))\n",
    "sum_num = 0\n",
    "for s in str_fac:\n",
    "    sum_num += int(s)\n",
    "print sum_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###12. 오일러 문제 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31626\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def div_sum(num):\n",
    "    #print \"num : \" + str(num)\n",
    "    if num == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        sum_num = 1\n",
    "        pivot = int(math.sqrt(num))\n",
    "        for i in range(2, pivot):\n",
    "            if num % i == 0:\n",
    "                sum_num += i\n",
    "                sum_num += num / i\n",
    "                #print i, num / i\n",
    "        if pivot * pivot == num:\n",
    "            num += pivot\n",
    "    #print \"end\"\n",
    "    return sum_num\n",
    "        \n",
    "sum_all = 0\n",
    "for i in range(2,10001):\n",
    "    sum_num = div_sum(i)\n",
    "    temp = div_sum(sum_num)\n",
    "    if temp == i and i != sum_num:\n",
    "        sum_all += i\n",
    "print sum_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###13. 이번에는 Assignment 3을 다시 확장/변형하여 다음과 같은 조건을 만족하도록 구현하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 새로운 클래스 WebWordsFrequency를 정의하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.WebWordsFrequency instance at 0x0000000003DFBD48>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "\n",
    "wwf = WebWordsFrequency()\n",
    "print wwf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 생성자에 URL을 0개에서 임의의 개수를 넣을 수 있도록 생성자 인수를 가변인수로 정의하여 각각의 URL을 리스트 자료형에 유지하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com']\n",
      "['http://www.cnn.com', 'http://www.times.com']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "print w1.urls\n",
    "w2 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com') \n",
    "print w2.urls\n",
    "w3 = WebWordsFrequency() \n",
    "print w3.urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) addUrl() 메소드를 구현하여 인스턴스를 생성한 이후에도 URL을 추가할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com']\n",
      "['http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com', 'https://github.com']\n",
      "['http://www.cnn.com', 'http://www.times.com']\n",
      "[]\n",
      "['http://stackoverflow.com']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "    \n",
    "    def addUrl(self, url):\n",
    "        self.urls.append(url)\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "print w1.urls\n",
    "w1.addUrl('https://github.com')\n",
    "print w1.urls\n",
    "w2 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com') \n",
    "print w2.urls\n",
    "w3 = WebWordsFrequency() \n",
    "print w3.urls\n",
    "w3.addUrl('http://stackoverflow.com')\n",
    "print w3.urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) removeUrl() 메소드를 구현하여 URL을 삭제할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com']\n",
      "['http://www.times.com', 'https://www.amazon.com']\n",
      "['http://www.cnn.com', 'http://www.times.com']\n",
      "['http://www.cnn.com', 'http://www.times.com']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "    \n",
    "    def addUrl(self, url):\n",
    "        self.urls.append(url)\n",
    "    \n",
    "    def removeUrl(self, url):\n",
    "        if url in self.urls:\n",
    "            self.urls.remove(url)\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "print w1.urls\n",
    "w1.removeUrl('http://www.cnn.com')\n",
    "print w1.urls\n",
    "w2 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com') \n",
    "print w2.urls\n",
    "w2.removeUrl('http://stackoverflow.com')\n",
    "print w2.urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) listUrls() 메소드를 구현하여 현재 등록된 모든 URL을 출력하는 기능을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.cnn.com\n",
      "http://www.times.com\n",
      "https://www.amazon.com\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "    \n",
    "    def addUrl(self, url):\n",
    "        self.urls.append(url)\n",
    "    \n",
    "    def removeUrl(self, url):\n",
    "        if url in self.urls:\n",
    "            self.urls.remove(url)\n",
    "            \n",
    "    def listUrls(self):\n",
    "        for url in self.urls:\n",
    "            print url\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "w1.listUrls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) getWordsFrequency() 메소드를 구현하여 각 URL의 웹페이지들을 종합적으로 분석한 단어 출현 빈도 사전을 반환하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('raquo', 34),\n",
       " ('more', 22),\n",
       " ('new', 19),\n",
       " ('times', 18),\n",
       " ('et', 15),\n",
       " ('review', 15),\n",
       " ('your', 15),\n",
       " ('opinion', 14),\n",
       " ('books', 14),\n",
       " ('home', 14),\n",
       " ('oped', 11),\n",
       " ('news', 11),\n",
       " ('arts', 11),\n",
       " ('an', 11),\n",
       " ('us', 11),\n",
       " ('nbsp', 10),\n",
       " ('pm', 10),\n",
       " ('video', 9),\n",
       " ('food', 9),\n",
       " ('search', 8),\n",
       " ('san', 8),\n",
       " ('amazon', 8),\n",
       " ('bernardino', 8),\n",
       " ('magazine', 8),\n",
       " ('all', 7),\n",
       " ('go', 7),\n",
       " ('health', 7),\n",
       " ('movies', 7),\n",
       " ('york', 7),\n",
       " ('fashion', 7),\n",
       " ('services', 7),\n",
       " ('see', 7),\n",
       " ('sports', 7),\n",
       " ('mass', 7),\n",
       " ('trump', 6),\n",
       " ('next', 6),\n",
       " ('about', 6),\n",
       " ('science', 6),\n",
       " ('prime', 6),\n",
       " ('climate', 6),\n",
       " ('subscriptions', 6),\n",
       " ('business', 6),\n",
       " ('digital', 6),\n",
       " ('everything', 5),\n",
       " ('spike', 5),\n",
       " ('high', 5),\n",
       " ('travel', 5),\n",
       " ('get', 5),\n",
       " ('after', 5),\n",
       " ('how', 5),\n",
       " ('house', 5),\n",
       " ('one', 5),\n",
       " ('top', 5),\n",
       " ('lee\\xe2\\x80\\x99s', 5),\n",
       " ('do', 5),\n",
       " ('best', 5),\n",
       " ('\\xe2\\x80\\x98the', 5),\n",
       " ('am', 5),\n",
       " ('\\xe2\\x80\\x98chiraq\\xe2\\x80\\x99', 5),\n",
       " ('world', 5),\n",
       " ('education', 5),\n",
       " ('amp', 5),\n",
       " ('paris', 4),\n",
       " ('gun', 4),\n",
       " ('what', 4),\n",
       " ('shootings', 4),\n",
       " ('journalists', 4),\n",
       " ('learn', 4),\n",
       " ('estate', 4),\n",
       " ('his', 4),\n",
       " ('beauty', 4),\n",
       " ('style', 4),\n",
       " ('2015', 4),\n",
       " ('landlord', 4),\n",
       " ('shooting', 4),\n",
       " ('rates', 4),\n",
       " ('jobs', 4),\n",
       " ('online', 4),\n",
       " ('who', 4),\n",
       " ('shop', 4),\n",
       " ('crossword', 4),\n",
       " ('games', 4),\n",
       " ('subscribe', 4),\n",
       " ('he', 4),\n",
       " ('tv', 4),\n",
       " ('real', 4),\n",
       " ('guide', 4),\n",
       " ('dies', 4),\n",
       " ('publishing', 4),\n",
       " ('when', 4),\n",
       " ('todays', 3),\n",
       " ('pledged', 3),\n",
       " ('room', 3),\n",
       " ('school', 3),\n",
       " ('did', 3),\n",
       " ('try', 3),\n",
       " ('profiles', 3),\n",
       " ('nbc', 3),\n",
       " ('free', 3),\n",
       " ('credit', 3),\n",
       " ('scandal', 3),\n",
       " ('wiz', 3),\n",
       " ('insider', 3),\n",
       " ('music', 3),\n",
       " ('door', 3),\n",
       " ('baby', 3),\n",
       " ('suspects\\xe2\\x80\\x99', 3),\n",
       " ('clothing', 3),\n",
       " ('seacrest', 3),\n",
       " ('extrascnn', 3),\n",
       " ('rubio', 3),\n",
       " ('nyc', 3),\n",
       " ('stop', 3),\n",
       " ('fifa', 3),\n",
       " ('exclusive', 3),\n",
       " ('over', 3),\n",
       " ('cruise', 3),\n",
       " ('its', 3),\n",
       " ('sunday', 3),\n",
       " ('shoes', 3),\n",
       " ('now', 3),\n",
       " ('living', 3),\n",
       " ('deals', 3),\n",
       " ('azcnn', 3),\n",
       " ('apps', 3),\n",
       " ('open', 3),\n",
       " ('city', 3),\n",
       " ('store', 3),\n",
       " ('off', 3),\n",
       " ('rampage', 3),\n",
       " ('were', 3),\n",
       " ('say', 3),\n",
       " ('events', 3),\n",
       " ('won\\xe2\\x80\\x99t', 3),\n",
       " ('mobiletools', 3),\n",
       " ('most', 3),\n",
       " ('adopt', 3),\n",
       " ('designer', 3),\n",
       " ('debate', 3),\n",
       " ('title', 3),\n",
       " ('edition', 3),\n",
       " ('men', 3),\n",
       " ('genderneutral', 3),\n",
       " ('david', 3),\n",
       " ('way', 3),\n",
       " ('allegiance', 3),\n",
       " ('kitchen', 3),\n",
       " ('shopping', 3),\n",
       " ('sales', 3),\n",
       " ('editorial', 3),\n",
       " ('site', 3),\n",
       " ('terrorism', 3),\n",
       " ('truckers', 3),\n",
       " ('kindle', 3),\n",
       " ('live\\xe2\\x80\\x99', 3),\n",
       " ('\\xe2\\x80\\x98mx\\xe2\\x80\\x99', 3),\n",
       " ('ny', 3),\n",
       " ('money', 3),\n",
       " ('loading', 3),\n",
       " ('theater', 3),\n",
       " ('lets', 3),\n",
       " ('book', 3),\n",
       " ('some', 3),\n",
       " ('donald', 3),\n",
       " ('courtesy', 3),\n",
       " ('act', 3),\n",
       " ('easy', 3),\n",
       " ('sections', 3),\n",
       " ('line', 3),\n",
       " ('made', 3),\n",
       " ('isis', 3),\n",
       " ('whether', 3),\n",
       " ('right', 3),\n",
       " ('politics', 3),\n",
       " ('ship', 3),\n",
       " ('know', 3),\n",
       " ('10', 3),\n",
       " ('nytimescom', 3),\n",
       " ('skip', 2),\n",
       " ('illustrated', 2),\n",
       " ('gang', 2),\n",
       " ('include', 2),\n",
       " ('retire', 2),\n",
       " ('homes', 2),\n",
       " ('continues', 2),\n",
       " ('automobiles', 2),\n",
       " ('why', 2),\n",
       " ('ryan', 2),\n",
       " ('temple', 2),\n",
       " ('race', 2),\n",
       " ('battle', 2),\n",
       " ('phones', 2),\n",
       " ('interview', 2),\n",
       " ('talks', 2),\n",
       " ('rate', 2),\n",
       " ('multimedia', 2),\n",
       " ('access', 2),\n",
       " ('inyour', 2),\n",
       " ('suspect', 2),\n",
       " ('international', 2),\n",
       " ('public', 2),\n",
       " ('seeks', 2),\n",
       " ('musical', 2),\n",
       " ('legend', 2),\n",
       " ('study', 2),\n",
       " ('women', 2),\n",
       " ('gear', 2),\n",
       " ('action', 2),\n",
       " ('1248', 2),\n",
       " ('had', 2),\n",
       " ('options', 2),\n",
       " ('cardamazoncom', 2),\n",
       " ('mamet\\xe2\\x80\\x99s', 2),\n",
       " ('cowardly', 2),\n",
       " ('sicily', 2),\n",
       " ('fbi', 2),\n",
       " ('fed', 2),\n",
       " ('from', 2),\n",
       " ('takedown', 2),\n",
       " ('espa\\xc3\\xb1oltvtv', 2),\n",
       " ('live', 2),\n",
       " ('contributors', 2),\n",
       " ('accessories', 2),\n",
       " ('cards', 2),\n",
       " ('growing', 2),\n",
       " ('itaposs', 2),\n",
       " ('evangelicals', 2),\n",
       " ('computers', 2),\n",
       " ('doll\\xe2\\x80\\x99', 2),\n",
       " ('indie', 2),\n",
       " ('subsidies', 2),\n",
       " ('soup', 2),\n",
       " ('please', 2),\n",
       " ('breaking', 2),\n",
       " ('nyt', 2),\n",
       " ('speaks', 2),\n",
       " ('economy', 2),\n",
       " ('brands', 2),\n",
       " ('man', 2),\n",
       " ('hanukkah', 2),\n",
       " ('so', 2),\n",
       " ('talk', 2),\n",
       " ('wine', 2),\n",
       " ('rye', 2),\n",
       " ('schwartz', 2),\n",
       " ('move', 2),\n",
       " ('murray', 2),\n",
       " ('report', 2),\n",
       " ('paper', 2),\n",
       " ('scott', 2),\n",
       " ('jim', 2),\n",
       " ('worldwidefeaturestravelall', 2),\n",
       " ('amazonsell', 2),\n",
       " ('texas', 2),\n",
       " ('toys', 2),\n",
       " ('good', 2),\n",
       " ('sewing', 2),\n",
       " ('taliban', 2),\n",
       " ('emerald', 2),\n",
       " ('killed', 2),\n",
       " ('countries', 2),\n",
       " ('arrested', 2),\n",
       " ('en', 2),\n",
       " ('ring', 2),\n",
       " ('network', 2),\n",
       " ('content', 2),\n",
       " ('story', 2),\n",
       " ('brooks', 2),\n",
       " ('california', 2),\n",
       " ('featuresopinionsireportmore\\xe2\\x80\\xa6photosweathercnn', 2),\n",
       " ('listings', 2),\n",
       " ('keep', 2),\n",
       " ('american', 2),\n",
       " ('pilots', 2),\n",
       " ('insist', 2),\n",
       " ('vote', 2),\n",
       " ('attack', 2),\n",
       " ('upshot', 2),\n",
       " ('white', 2),\n",
       " ('reminder', 2),\n",
       " ('behind', 2),\n",
       " ('than', 2),\n",
       " ('matter', 2),\n",
       " ('iberianinspired', 2),\n",
       " ('well', 2),\n",
       " ('mogul', 2),\n",
       " ('have', 2),\n",
       " ('viewed', 2),\n",
       " ('discounts', 2),\n",
       " ('cell', 2),\n",
       " ('also', 2),\n",
       " ('square', 2),\n",
       " ('luxury', 2),\n",
       " ('moscow', 2),\n",
       " ('play', 2),\n",
       " ('mobile', 2),\n",
       " ('hungry', 2),\n",
       " ('tech', 2),\n",
       " ('amazoncom', 2),\n",
       " ('videosshowscnn', 2),\n",
       " ('chowder', 2),\n",
       " ('playbook', 2),\n",
       " ('help', 2),\n",
       " ('tape', 2),\n",
       " ('storage', 2),\n",
       " ('photography', 2),\n",
       " ('watch', 2),\n",
       " ('television', 2),\n",
       " ('employers', 2),\n",
       " ('killers', 2),\n",
       " ('westchester', 2),\n",
       " ('gray', 2),\n",
       " ('covering', 2),\n",
       " ('fixed', 2),\n",
       " ('todayrsquos', 2),\n",
       " ('48', 2),\n",
       " ('view', 2),\n",
       " ('art', 2),\n",
       " ('sex', 2),\n",
       " ('australia', 2),\n",
       " ('college', 2),\n",
       " ('creating', 2),\n",
       " ('suspects', 2),\n",
       " ('said', 2),\n",
       " ('ways', 2),\n",
       " ('editionusinternationalarabicespa\\xc3\\xb1olset', 2),\n",
       " ('\\xe2\\x80\\x98china', 2),\n",
       " ('ends', 2),\n",
       " ('terms', 2),\n",
       " ('web', 2),\n",
       " ('ask', 2),\n",
       " ('latkes', 2),\n",
       " ('useprivacy', 2),\n",
       " ('officer', 2),\n",
       " ('baltimore', 2),\n",
       " ('tough', 2),\n",
       " ('sweet', 2),\n",
       " ('100', 2),\n",
       " ('treat', 2),\n",
       " ('kids', 2),\n",
       " ('case', 2),\n",
       " ('killings', 2),\n",
       " ('look', 2),\n",
       " ('investigating', 2),\n",
       " ('media\\xe2\\x80\\x99s', 2),\n",
       " ('vs', 2),\n",
       " ('technology', 2),\n",
       " ('denial', 2),\n",
       " ('make', 2),\n",
       " ('showsschedulefaces', 2),\n",
       " ('barbed', 2),\n",
       " ('weiland', 2),\n",
       " ('center', 2),\n",
       " ('pacino', 2),\n",
       " ('weapon', 2),\n",
       " ('relief', 2),\n",
       " ('corporate', 2),\n",
       " ('left', 2),\n",
       " ('executive', 2),\n",
       " ('yet', 2),\n",
       " ('america\\xe2\\x80\\x99s', 2),\n",
       " ('thinking', 2),\n",
       " ('workers', 2),\n",
       " ('dance', 2),\n",
       " ('win', 2),\n",
       " ('has', 2),\n",
       " ('marco', 2),\n",
       " ('articles', 2),\n",
       " ('nbspcomments', 2),\n",
       " ('grim', 2),\n",
       " ('like', 2),\n",
       " ('65', 2),\n",
       " ('learning', 2),\n",
       " ('pet', 2),\n",
       " ('delaware', 2),\n",
       " ('legal', 2),\n",
       " ('cnn', 2),\n",
       " ('leader', 2),\n",
       " ('payment', 2),\n",
       " ('raise', 2),\n",
       " ('hearing', 2),\n",
       " ('faith', 2),\n",
       " ('stone', 2),\n",
       " ('rare', 2),\n",
       " ('vengeance', 2),\n",
       " ('block', 2),\n",
       " ('puzzle', 2),\n",
       " ('down', 2),\n",
       " ('homeless', 2),\n",
       " ('often', 2),\n",
       " ('housing', 2),\n",
       " ('gift', 2),\n",
       " ('eastafricaeuropeamericasvideomust', 2),\n",
       " ('editor', 2),\n",
       " ('series', 2),\n",
       " ('biggest', 2),\n",
       " ('singer', 2),\n",
       " ('delivery', 2),\n",
       " ('podcast', 2),\n",
       " ('longer', 2),\n",
       " ('friday', 2),\n",
       " ('official', 2),\n",
       " ('up', 2),\n",
       " ('economic', 2),\n",
       " ('electronics', 2),\n",
       " ('sale', 2),\n",
       " ('orders', 2),\n",
       " ('inc', 2),\n",
       " ('obituaries', 2),\n",
       " ('green', 2),\n",
       " ('you', 2),\n",
       " ('kansas', 2),\n",
       " ('wars', 2),\n",
       " ('gifts', 2),\n",
       " ('tools', 2),\n",
       " ('photo', 1),\n",
       " ('coach', 1),\n",
       " ('accountyour', 1),\n",
       " ('arabiccnn', 1),\n",
       " ('cofounded', 1),\n",
       " ('ganz', 1),\n",
       " ('suburban', 1),\n",
       " ('child', 1),\n",
       " ('month', 1),\n",
       " ('protest', 1),\n",
       " ('gt', 1),\n",
       " ('groceries', 1),\n",
       " ('skin', 1),\n",
       " ('papervideo', 1),\n",
       " ('appetite', 1),\n",
       " ('involved', 1),\n",
       " ('religious', 1),\n",
       " ('carpet', 1),\n",
       " ('leadershipcnn', 1),\n",
       " ('newstoggle', 1),\n",
       " ('essentials', 1),\n",
       " ('show', 1),\n",
       " ('editors', 1),\n",
       " ('thursday', 1),\n",
       " ('0', 1),\n",
       " ('daniel', 1),\n",
       " ('supplies', 1),\n",
       " ('macfarquhar', 1),\n",
       " ('innis', 1),\n",
       " ('guarantee', 1),\n",
       " ('pledges', 1),\n",
       " ('supreme', 1),\n",
       " ('bestselling', 1),\n",
       " ('adviser', 1),\n",
       " ('updated', 1),\n",
       " ('garden', 1),\n",
       " ('far', 1),\n",
       " ('automotive', 1),\n",
       " ('sellers', 1),\n",
       " ('deviceshelp', 1),\n",
       " ('facebook', 1),\n",
       " ('additional', 1),\n",
       " ('suggests', 1),\n",
       " ('philanthropic', 1),\n",
       " ('kingdom', 1),\n",
       " ('difference', 1),\n",
       " ('died', 1),\n",
       " ('treating', 1),\n",
       " ('productsselfpublish', 1),\n",
       " ('zappos', 1),\n",
       " ('cable', 1),\n",
       " ('mercurial', 1),\n",
       " ('ushelptranscriptslicense', 1),\n",
       " ('michael', 1),\n",
       " ('solved', 1),\n",
       " ('highway', 1),\n",
       " ('car', 1),\n",
       " ('depository', 1),\n",
       " ('settings', 1),\n",
       " ('caryn', 1),\n",
       " ('enjoy', 1),\n",
       " ('bill', 1),\n",
       " ('says', 1),\n",
       " ('uscareersabout', 1),\n",
       " ('reims', 1),\n",
       " ('trend', 1),\n",
       " ('aides', 1),\n",
       " ('1124', 1),\n",
       " ('direct', 1),\n",
       " ('cyber', 1),\n",
       " ('1127', 1),\n",
       " ('past', 1),\n",
       " ('cost', 1),\n",
       " ('pass', 1),\n",
       " ('judd', 1),\n",
       " ('leadershipinternational', 1),\n",
       " ('uswork', 1),\n",
       " ('victor', 1),\n",
       " ('index', 1),\n",
       " ('paintings', 1),\n",
       " ('section', 1),\n",
       " ('while', 1),\n",
       " ('week\\xe2\\x80\\x99s', 1),\n",
       " ('supporter', 1),\n",
       " ('version', 1),\n",
       " ('goes', 1),\n",
       " ('toll', 1),\n",
       " ('net', 1),\n",
       " ('appeal', 1),\n",
       " ('wwwamazoncomaccess', 1),\n",
       " ('1235', 1),\n",
       " ('full', 1),\n",
       " ('facebookcnn', 1),\n",
       " ('createspace', 1),\n",
       " ('notredame', 1),\n",
       " ('whose', 1),\n",
       " ('gwftgrdesktopherokindleb', 1),\n",
       " ('mr', 1),\n",
       " ('richest', 1),\n",
       " ('affiliates', 1),\n",
       " ('hundreds', 1),\n",
       " ('explore', 1),\n",
       " ('apartment', 1),\n",
       " ('china', 1),\n",
       " ('6pm', 1),\n",
       " ('meet', 1),\n",
       " ('path', 1),\n",
       " ('november', 1),\n",
       " ('longdistance', 1),\n",
       " ('106', 1),\n",
       " ('change', 1),\n",
       " ('landmarks', 1),\n",
       " ('india', 1),\n",
       " ('bible', 1),\n",
       " ('governor\\xe2\\x80\\x99s', 1),\n",
       " ('luggage', 1),\n",
       " ('shift', 1),\n",
       " ('studied', 1),\n",
       " ('shoulders', 1),\n",
       " ('experience', 1),\n",
       " ('leaving', 1),\n",
       " ('\\xe2\\x80\\x98invisible', 1),\n",
       " ('products', 1),\n",
       " ('menu', 1),\n",
       " ('christmas\\xe2\\x80\\x99', 1),\n",
       " ('navigation', 1),\n",
       " ('vinyl', 1),\n",
       " ('useful', 1),\n",
       " ('wearables', 1),\n",
       " ('ground', 1),\n",
       " ('limp', 1),\n",
       " ('sign', 1),\n",
       " ('threes', 1),\n",
       " ('commandments', 1),\n",
       " ('ordersshipping', 1),\n",
       " ('put', 1),\n",
       " ('primereturns', 1),\n",
       " ('you\\xe2\\x80\\x99re', 1),\n",
       " ('appliances', 1),\n",
       " ('stern', 1),\n",
       " ('manage', 1),\n",
       " ('classifieds', 1),\n",
       " ('hammer\\xe2\\x80\\x99', 1),\n",
       " ('market', 1),\n",
       " ('republicans\\xe2\\x80\\x99', 1),\n",
       " ('prove', 1),\n",
       " ('resigns', 1),\n",
       " ('wordplay', 1),\n",
       " ('card', 1),\n",
       " ('mysterious', 1),\n",
       " ('candidates', 1),\n",
       " ('panel', 1),\n",
       " ('ads\\xc2\\xa9', 1),\n",
       " ('amazonglobal', 1),\n",
       " ('flat', 1),\n",
       " ('started', 1),\n",
       " ('oscar', 1),\n",
       " ('company', 1),\n",
       " ('musician', 1),\n",
       " ('benchmark', 1),\n",
       " ('improve', 1),\n",
       " ('lore', 1),\n",
       " ('train', 1),\n",
       " ('jungleecom', 1),\n",
       " ('effort', 1),\n",
       " ('must', 1),\n",
       " ('account', 1),\n",
       " ('animals', 1),\n",
       " ('timesvideo', 1),\n",
       " ('skill\\xe2\\x80\\x99', 1),\n",
       " ('rights', 1),\n",
       " ('challenge', 1),\n",
       " ('work', 1),\n",
       " ('cat', 1),\n",
       " ('flagship', 1),\n",
       " ('nation\\xe2\\x80\\x99s', 1),\n",
       " ('condominium', 1),\n",
       " ('can', 1),\n",
       " ('making', 1),\n",
       " ('dewalt', 1),\n",
       " ('my', 1),\n",
       " ('amazonbecome', 1),\n",
       " ('control', 1),\n",
       " ('heart', 1),\n",
       " ('nursing', 1),\n",
       " ('december', 1),\n",
       " ('newsletters', 1),\n",
       " ('wilsonthe', 1),\n",
       " ('hauser', 1),\n",
       " ('leadfootball', 1),\n",
       " ('accounttryprimeyourlistscart', 1),\n",
       " ('chic', 1),\n",
       " ('littmann', 1),\n",
       " ('audible', 1),\n",
       " ('aging', 1),\n",
       " ('stethoscopes', 1),\n",
       " ('1053', 1),\n",
       " ('end', 1),\n",
       " ('winter', 1),\n",
       " ('hannah', 1),\n",
       " ('writers', 1),\n",
       " ('ornately', 1),\n",
       " ('newsworldsporttechnologyentertainmentstyletravelmoneyregionsuschinaasiamiddle',\n",
       "  1),\n",
       " ('map', 1),\n",
       " ('product', 1),\n",
       " ('massacre', 1),\n",
       " ('explorer', 1),\n",
       " ('16uk', 1),\n",
       " ('critics', 1),\n",
       " ('spot', 1),\n",
       " ('roads', 1),\n",
       " ('scalable', 1),\n",
       " ('islamic', 1),\n",
       " ('wrong', 1),\n",
       " ('notebook', 1),\n",
       " ('court', 1),\n",
       " ('lifting', 1),\n",
       " ('included', 1),\n",
       " ('danny', 1),\n",
       " ('third', 1),\n",
       " ('life', 1),\n",
       " ('usbecome', 1),\n",
       " ('fever', 1),\n",
       " ('chief', 1),\n",
       " ('broadcasting', 1),\n",
       " ('road', 1),\n",
       " ('things', 1),\n",
       " ('\\xe2\\x80\\x98star', 1),\n",
       " ('feedback', 1),\n",
       " ('thousands', 1),\n",
       " ('131', 1),\n",
       " ('committee', 1),\n",
       " ('headings', 1),\n",
       " ('letters', 1),\n",
       " ('blocked', 1),\n",
       " ('25', 1),\n",
       " ('group', 1),\n",
       " ('aid', 1),\n",
       " ('internationally', 1),\n",
       " ('duplex', 1),\n",
       " ('warehouse', 1),\n",
       " ('better', 1),\n",
       " ('edits', 1),\n",
       " ('puerto', 1),\n",
       " ('schmidt', 1),\n",
       " ('sourcesinside', 1),\n",
       " ('productsamazoncom', 1),\n",
       " ('killer', 1),\n",
       " ('acx', 1),\n",
       " ('multimediaphotos', 1),\n",
       " ('very', 1),\n",
       " ('band', 1),\n",
       " ('shopbop', 1),\n",
       " ('grows', 1),\n",
       " ('highlevel', 1),\n",
       " ('minimalist', 1),\n",
       " ('ancient', 1),\n",
       " ('holiday', 1),\n",
       " ('artsbeat', 1),\n",
       " ('neutrality', 1),\n",
       " ('sundays', 1),\n",
       " ('powell', 1),\n",
       " ('shenanigans', 1),\n",
       " ('follow', 1),\n",
       " ('rock', 1),\n",
       " ('projectquick', 1),\n",
       " ('found', 1),\n",
       " ('entirely', 1),\n",
       " ('goodreads', 1),\n",
       " ('85', 1),\n",
       " ('investigators', 1),\n",
       " ('development', 1),\n",
       " ('neil', 1),\n",
       " ('female', 1),\n",
       " ('reduce', 1),\n",
       " ('tighten', 1),\n",
       " ('pantry', 1),\n",
       " ('faithdriven', 1),\n",
       " ('year', 1),\n",
       " ('teams', 1),\n",
       " ('math', 1),\n",
       " ('out', 1),\n",
       " ('blacks', 1),\n",
       " ('entertainment', 1),\n",
       " ('policyadchoicesadvertise', 1),\n",
       " ('since', 1),\n",
       " ('islamist', 1),\n",
       " ('may', 1),\n",
       " ('investigation', 1),\n",
       " ('usabout', 1),\n",
       " ('7', 1),\n",
       " ('internet', 1),\n",
       " ('print', 1),\n",
       " ('211000', 1),\n",
       " ('shortly', 1),\n",
       " ('calif', 1),\n",
       " ('gop', 1),\n",
       " ('red', 1),\n",
       " ('shows', 1),\n",
       " ('bistro', 1),\n",
       " ('website', 1),\n",
       " ('earlier', 1),\n",
       " ('africa\\xe2\\x80\\x99s', 1),\n",
       " ('worldcnn', 1),\n",
       " ('frank', 1),\n",
       " ('million', 1),\n",
       " ('espa\\xc3\\xb1olcnn', 1),\n",
       " ('quite', 1),\n",
       " ('zuckerberg', 1),\n",
       " ('extraordinary', 1),\n",
       " ('disputes', 1),\n",
       " ('marino', 1),\n",
       " ('mimi', 1),\n",
       " ('region', 1),\n",
       " ('reporters', 1),\n",
       " ('fabric', 1),\n",
       " ('applications', 1),\n",
       " ('could', 1),\n",
       " ('florida', 1),\n",
       " ('membership', 1),\n",
       " ('broton', 1),\n",
       " ('place', 1),\n",
       " ('w', 1),\n",
       " ('signature', 1),\n",
       " ('corrections', 1),\n",
       " ('samesex', 1),\n",
       " ('austin', 1),\n",
       " ('think', 1),\n",
       " ('first', 1),\n",
       " ('cheese', 1),\n",
       " ('major', 1),\n",
       " ('industrial', 1),\n",
       " ('features', 1),\n",
       " ('analytics', 1),\n",
       " ('powerful', 1),\n",
       " ('arsenal', 1),\n",
       " ('britain8217s', 1),\n",
       " ('americans', 1),\n",
       " ('normality', 1),\n",
       " ('governor', 1),\n",
       " ('traveler', 1),\n",
       " ('message', 1),\n",
       " ('diaperscom', 1),\n",
       " ('grocery', 1),\n",
       " ('rented', 1),\n",
       " ('victimsunspeakable', 1),\n",
       " ('1996', 1),\n",
       " ('heads', 1),\n",
       " ('service', 1),\n",
       " ('privacy', 1),\n",
       " ('gourmet', 1),\n",
       " ('system', 1),\n",
       " ('ussell', 1),\n",
       " ('download', 1),\n",
       " ('listed', 1),\n",
       " ('convene', 1),\n",
       " ('john', 1),\n",
       " ('bits', 1),\n",
       " ('urban', 1),\n",
       " ('weddings', 1),\n",
       " ('stars', 1),\n",
       " ('pointscredit', 1),\n",
       " ('openbox', 1),\n",
       " ('hun', 1),\n",
       " ('jamie', 1),\n",
       " ('abebooks', 1),\n",
       " ('yoyocom', 1),\n",
       " ('lengthier', 1),\n",
       " ('thai', 1),\n",
       " ('copy', 1),\n",
       " ('convinced', 1),\n",
       " ('wars\\xe2\\x80\\x99', 1),\n",
       " ('mercy', 1),\n",
       " ('colleagues', 1),\n",
       " ('cracks', 1),\n",
       " ('target', 1),\n",
       " ('emailedmost', 1),\n",
       " ('myhabit', 1),\n",
       " ('likely', 1),\n",
       " ('225', 1),\n",
       " ('nations', 1),\n",
       " ('recording', 1),\n",
       " ('greg', 1),\n",
       " ('boehler', 1),\n",
       " ('polishing', 1),\n",
       " ('design', 1),\n",
       " ('dane', 1),\n",
       " ('happy', 1),\n",
       " ('browser', 1),\n",
       " ('woot', 1),\n",
       " ('terrorism\\xe2\\x80\\x9d', 1),\n",
       " ('remained', 1),\n",
       " ('reviews', 1),\n",
       " ('improbability', 1),\n",
       " ('reader', 1),\n",
       " ('voices', 1),\n",
       " ('rewards', 1),\n",
       " ('imdb', 1),\n",
       " ('rent', 1),\n",
       " ('storiespoll', 1),\n",
       " ('close', 1),\n",
       " ('turner', 1),\n",
       " ('seek', 1),\n",
       " ('any', 1),\n",
       " ('year\\xe2\\x80\\x99s', 1),\n",
       " ('sell', 1),\n",
       " ('uscontact', 1),\n",
       " ('friday\\xe2\\x80\\x99s', 1),\n",
       " ('agency', 1),\n",
       " ('krugman', 1),\n",
       " ('makers', 1),\n",
       " ('note', 1),\n",
       " ('donor', 1),\n",
       " ('worldwide', 1),\n",
       " ('200', 1),\n",
       " ('added', 1),\n",
       " ('marketplaceamazon', 1),\n",
       " ('quote', 1),\n",
       " ('distraction', 1),\n",
       " ('kean', 1),\n",
       " ('freddie', 1),\n",
       " ('75', 1),\n",
       " ('hired', 1),\n",
       " ('sponsored', 1),\n",
       " ('recently', 1),\n",
       " ('allamazon', 1),\n",
       " ('prestige', 1),\n",
       " ('pages', 1),\n",
       " ('unsparing', 1),\n",
       " ('solidifies', 1),\n",
       " ('michelle', 1),\n",
       " ('cuban', 1),\n",
       " ('1040', 1),\n",
       " ('clear', 1),\n",
       " ('m', 1),\n",
       " ('tooth', 1),\n",
       " ('actionable', 1),\n",
       " ('vinemarketcom', 1),\n",
       " ('hodari', 1),\n",
       " ('patio', 1),\n",
       " ('clearing', 1),\n",
       " ('occasion', 1),\n",
       " ('came', 1),\n",
       " ('laws', 1),\n",
       " ('relationsamazon', 1),\n",
       " ('shot', 1),\n",
       " ('amazoncomtodays', 1),\n",
       " ('journeys', 1),\n",
       " ('text', 1),\n",
       " ('queen', 1),\n",
       " ('celebrities', 1),\n",
       " ('contemporary', 1),\n",
       " ('russian', 1),\n",
       " ('outdoor', 1),\n",
       " ('fino', 1),\n",
       " ('cds', 1),\n",
       " ('fear', 1),\n",
       " ('fine', 1),\n",
       " ('caper', 1),\n",
       " ('current', 1),\n",
       " ('cameras', 1),\n",
       " ('upgrade', 1),\n",
       " ('160160160girls', 1),\n",
       " ('office', 1),\n",
       " ('improvement', 1),\n",
       " ('much', 1),\n",
       " ('unemployment', 1),\n",
       " ('minnesota', 1),\n",
       " ('controls', 1),\n",
       " ('222', 1),\n",
       " ('rico', 1),\n",
       " ('air', 1),\n",
       " ('inherited', 1),\n",
       " ('marriage', 1),\n",
       " ('watching', 1),\n",
       " ('population', 1),\n",
       " ('local', 1),\n",
       " ('mortality', 1),\n",
       " ('dispute', 1),\n",
       " ('sued', 1),\n",
       " ('dvds', 1),\n",
       " ('bonds', 1),\n",
       " ('familiar', 1),\n",
       " ('honda', 1),\n",
       " ('hid', 1),\n",
       " ('nearly', 1),\n",
       " ('katharine', 1),\n",
       " ('leases', 1),\n",
       " ('falling', 1),\n",
       " ('14', 1),\n",
       " ('afterschoolcom', 1),\n",
       " ('de', 1),\n",
       " ('cambodians', 1),\n",
       " ('beautybarcom', 1),\n",
       " ('textbooks', 1),\n",
       " ('rothschild', 1),\n",
       " ('businesssell', 1),\n",
       " ('affluent', 1),\n",
       " ('comics', 1),\n",
       " ('stuff', 1),\n",
       " ('bombs', 1),\n",
       " ('draft', 1),\n",
       " ('release', 1),\n",
       " ('tightening', 1),\n",
       " ('where', 1),\n",
       " ('set', 1),\n",
       " ('questions', 1),\n",
       " ('our', 1),\n",
       " ('problem', 1),\n",
       " ('humans', 1),\n",
       " ('lamar', 1),\n",
       " ('officials', 1),\n",
       " ('migration', 1),\n",
       " ('sen', 1),\n",
       " ('activities', 1),\n",
       " ('cardssellhelp', 1),\n",
       " ('defends', 1),\n",
       " ('threats', 1),\n",
       " ('mortgage', 1),\n",
       " ('don\\xe2\\x80\\x99t', 1),\n",
       " ('artworld', 1),\n",
       " ('away', 1),\n",
       " ('sail', 1),\n",
       " ('familiarity', 1),\n",
       " ('kind', 1),\n",
       " ('tolls', 1),\n",
       " ('3', 1),\n",
       " ('bruni', 1),\n",
       " ('crisis', 1),\n",
       " ('routine', 1),\n",
       " ('vocals', 1),\n",
       " ('conditions', 1),\n",
       " ('email', 1),\n",
       " ('disgruntled', 1),\n",
       " ('bought', 1),\n",
       " ('warrior', 1),\n",
       " ('shockingwho', 1),\n",
       " ('screen', 1),\n",
       " ('monarchy', 1),\n",
       " ('carnagetop', 1),\n",
       " ('unlocked', 1),\n",
       " ('boss', 1),\n",
       " ('kids\\xe2\\x80\\x99', 1),\n",
       " ('we', 1),\n",
       " ('160160160men', 1),\n",
       " ('opposition', 1),\n",
       " ('opinionator', 1),\n",
       " ('outfit', 1),\n",
       " ('lawn', 1),\n",
       " ('accident', 1),\n",
       " ('accused', 1),\n",
       " ('wagcom', 1),\n",
       " ('many', 1),\n",
       " ('taking', 1),\n",
       " ('samaritan', 1),\n",
       " ('goldrickrab', 1),\n",
       " ('against', 1),\n",
       " ('crafts', 1),\n",
       " ('personal', 1),\n",
       " ('tour', 1),\n",
       " ('workplace', 1),\n",
       " ('bronx', 1),\n",
       " ('affiliateadvertise', 1),\n",
       " ('accountsign', 1),\n",
       " ('palace\\xe2\\x80\\x99s', 1),\n",
       " ('reasons', 1),\n",
       " ('2295', 1),\n",
       " ('hivmolotov', 1),\n",
       " ('60', 1),\n",
       " ('likes', 1),\n",
       " ('genes', 1),\n",
       " ('googlecnn', 1),\n",
       " ('townhouse', 1),\n",
       " ('poll', 1),\n",
       " ('smith', 1),\n",
       " ('apatow', 1),\n",
       " ('poem', 1),\n",
       " ('debt', 1),\n",
       " ('21stcentury', 1),\n",
       " ('asks', 1),\n",
       " ('union', 1),\n",
       " ('barry', 1),\n",
       " ('sara', 1),\n",
       " ('been', 1),\n",
       " ('mark', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "    \n",
    "    def getWordsFrequency(self):\n",
    "        sum_dict = {}\n",
    "        for url in self.urls:\n",
    "            d = self.count_pure_word(url)\n",
    "            for key in d.keys():\n",
    "                if sum_dict.has_key(key):\n",
    "                    sum_dict[key] += d[key]\n",
    "                else:\n",
    "                    sum_dict[key] = d[key]\n",
    "        l = sum_dict.items()\n",
    "        l.sort(cmp = lambda a,b : cmp(b[1], a[1]))\n",
    "        return l    \n",
    "    \n",
    "    def addUrl(self, url):\n",
    "        self.urls.append(url)\n",
    "    \n",
    "    def removeUrl(self, url):\n",
    "        if url in self.urls:\n",
    "            self.urls.remove(url)\n",
    "            \n",
    "    def listUrls(self):\n",
    "        for url in self.urls:\n",
    "            print url\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "w1.getWordsFrequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) getMaxFreqencyWords() 메소드를 구현하여 각 URL의 웹페이지들을 종합적으로 분석한 단어 출현 빈도 사전에서 가장 많이 출현한 단어 리스트를 반환하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raquo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import urllib2\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "class WebWordsFrequency:\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "    \n",
    "    def tag_delete(self, string):\n",
    "        for i in range(0, string.count('<!--')):\n",
    "            if string.find(\"<!--\") != -1:\n",
    "                string = string.replace(string[string.find(\"<!--\"):string.find(\"-->\")+3:],\"\")\n",
    "        for i in range(0,string.count(\"<\")):\n",
    "            if string.find(\"<\") != -1:\n",
    "                string = string.replace(string[string.find(\"<\"):string.find(\">\")+1:],\"\")\n",
    "\n",
    "        return string\n",
    "    \n",
    "    def javascript_delete(self, string):\n",
    "        for i in range(0, string.count('<script')):\n",
    "            if string.find(\"<script\") != -1:\n",
    "                string = string.replace(string[string.find(\"<script\"):string.find(\"</script>\")+9:],\"\")\n",
    "        return string\n",
    "\n",
    "    def stylesheet_delete(self, string):\n",
    "        for i in range(0, string.count('<style')):\n",
    "            if string.find(\"<style\") != -1:\n",
    "                string = string.replace(string[string.find(\"<style\"):string.find(\"</style>\")+8:],\"\")\n",
    "        return string\n",
    "\n",
    "    def count_pure_word(self, url):\n",
    "        source = urllib2.urlopen(url).read()\n",
    "\n",
    "        source = self.stylesheet_delete(source)\n",
    "        source = self.javascript_delete(source)\n",
    "        source = self.tag_delete(source)\n",
    "\n",
    "        words = source.split()\n",
    "\n",
    "        my_str = \" \".join(words)\n",
    "        for s in string.punctuation:\n",
    "            my_str = my_str.replace(s, \"\")\n",
    "        my_str = my_str.lower()\n",
    "\n",
    "        new_words = my_str.split()\n",
    "        new_dics = {}\n",
    "        for word in new_words:\n",
    "            if new_dics.has_key(word):\n",
    "                new_dics[word] += 1\n",
    "            else:\n",
    "                new_dics[word] = 1\n",
    "\n",
    "        en_punctuaction = [ 'a', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 's', 'such', 't', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']    \n",
    "        for en_punc in en_punctuaction:\n",
    "            new_dics.pop(en_punc, None)\n",
    "\n",
    "        return new_dics\n",
    "    \n",
    "    def getWordsFrequency(self):\n",
    "        sum_dict = {}\n",
    "        for url in self.urls:\n",
    "            d = self.count_pure_word(url)\n",
    "            for key in d.keys():\n",
    "                if sum_dict.has_key(key):\n",
    "                    sum_dict[key] += d[key]\n",
    "                else:\n",
    "                    sum_dict[key] = d[key]\n",
    "        l = sum_dict.items()\n",
    "        l.sort(cmp = lambda a,b : cmp(b[1], a[1]))\n",
    "        return l\n",
    "    \n",
    "    def getMaxFrequencyWords(self):\n",
    "        res = []\n",
    "        l = self.getWordsFrequency()\n",
    "        for i in range(0, len(l)):\n",
    "            res.append(l[i][0])\n",
    "            if l[i][1] != l[i+1][1]:\n",
    "                break            \n",
    "        if len(res) == 0:\n",
    "            res = None\n",
    "        return res\n",
    "    \n",
    "    def addUrl(self, url):\n",
    "        self.urls.append(url)\n",
    "    \n",
    "    def removeUrl(self, url):\n",
    "        if url in self.urls:\n",
    "            self.urls.remove(url)\n",
    "            \n",
    "    def listUrls(self):\n",
    "        for url in self.urls:\n",
    "            print url\n",
    "\n",
    "w1 = WebWordsFrequency('http://www.cnn.com', 'http://www.times.com', 'https://www.amazon.com') \n",
    "w1.getMaxFrequencyWords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###14. getWordsFrequency() 메소드를 오버라이드 하여 단어 출현 빈도를 내림 차순으로 정렬하여 리스트로 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('raquo', 34), ('more', 26), ('your', 21), ('new', 19), ('times', 18), ('review', 17), ('et', 15), ('opinion', 14), ('books', 14), ('home', 13)]\n",
      "\n",
      "[('photo', 1), ('coach', 1), ('accountyour', 1), ('cofounded', 1), ('ganz', 1), ('suburban', 1), ('child', 1), ('month', 1), ('ease', 1), ('protest', 1)]\n"
     ]
    }
   ],
   "source": [
    "class OrderedWebWordsFrequency(WebWordsFrequency):\n",
    "    def getWordsFrequency(self, **kwargs):\n",
    "        sum_dict = {}\n",
    "        for url in self.urls:\n",
    "            d = self.count_pure_word(url)\n",
    "            for key in d.keys():\n",
    "                if sum_dict.has_key(key):\n",
    "                    sum_dict[key] += d[key]\n",
    "                else:\n",
    "                    sum_dict[key] = d[key]\n",
    "        l = sum_dict.items()\n",
    "        if \"reverse\" not in kwargs:\n",
    "            kwargs[\"reverse\"] = False\n",
    "        if kwargs[\"reverse\"] == False:\n",
    "            l.sort(cmp = lambda a,b : cmp(b[1], a[1]))\n",
    "        else:\n",
    "            l.sort(cmp = lambda a,b : cmp(a[1], b[1]))\n",
    "        return l\n",
    "w4 = OrderedWebWordsFrequency('http://www.times.com', 'https://www.amazon.com', 'https://github.com')\n",
    "print w4.getWordsFrequency()[0:10]\n",
    "print\n",
    "print w4.getWordsFrequency(reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###15. 다음과 같은 코딩이 가능하도록 OrderedWebWordsFrequency 안에 반복자와 관련된 메소드를 추가하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('raquo', 34)\n",
      "('more', 25)\n",
      "('your', 21)\n",
      "('times', 19)\n",
      "('new', 17)\n",
      "('review', 16)\n",
      "('books', 14)\n",
      "('et', 13)\n",
      "('opinion', 13)\n",
      "('home', 12)\n",
      "('oped', 11)\n",
      "('arts', 11)\n",
      "('an', 11)\n",
      "('nbsp', 10)\n",
      "('github', 10)\n",
      "('pm', 9)\n",
      "('video', 8)\n",
      "('search', 8)\n",
      "('food', 8)\n",
      "('amazon', 8)\n",
      "('news', 8)\n",
      "('\\xe2\\x80\\x98the', 8)\n",
      "('see', 8)\n",
      "('magazine', 8)\n",
      "('us', 8)\n",
      "('go', 7)\n",
      "('movies', 7)\n",
      "('sports', 7)\n",
      "('about', 7)\n",
      "('health', 7)\n",
      "('one', 7)\n",
      "('fashion', 7)\n",
      "('services', 7)\n",
      "('you', 7)\n",
      "('all', 6)\n",
      "('wiz', 6)\n",
      "('from', 6)\n",
      "('get', 6)\n",
      "('york', 6)\n",
      "('prime', 6)\n",
      "('live\\xe2\\x80\\x99', 6)\n",
      "('business', 6)\n",
      "('subscriptions', 6)\n",
      "('digital', 6)\n",
      "('mass', 6)\n",
      "('sign', 5)\n",
      "('travel', 5)\n",
      "('open', 5)\n",
      "('top', 5)\n",
      "('san', 5)\n",
      "('shop', 5)\n",
      "('next', 5)\n",
      "('best', 5)\n",
      "('bernardino', 5)\n",
      "('make', 5)\n",
      "('world', 5)\n",
      "('everything', 5)\n",
      "('dies', 5)\n",
      "('software', 5)\n",
      "('whether', 5)\n",
      "('education', 5)\n",
      "('gun', 4)\n",
      "('try', 4)\n",
      "('what', 4)\n",
      "('learn', 4)\n",
      "('estate', 4)\n",
      "('high', 4)\n",
      "('room', 4)\n",
      "('trump', 4)\n",
      "('beauty', 4)\n",
      "('style', 4)\n",
      "('after', 4)\n",
      "('powerful', 4)\n",
      "('city', 4)\n",
      "('rates', 4)\n",
      "('free', 4)\n",
      "('online', 4)\n",
      "('debate', 4)\n",
      "('help', 4)\n",
      "('do', 4)\n",
      "('his', 4)\n",
      "('report', 4)\n",
      "('crossword', 4)\n",
      "('terms', 4)\n",
      "('games', 4)\n",
      "('tough', 4)\n",
      "('subscribe', 4)\n",
      "('tv', 4)\n",
      "('am', 4)\n",
      "('2015', 4)\n",
      "('jobs', 4)\n",
      "('case', 4)\n",
      "('week', 4)\n",
      "('real', 4)\n",
      "('projects', 4)\n",
      "('publishing', 4)\n",
      "('guide', 4)\n",
      "('tools', 4)\n",
      "('up', 4)\n",
      "('todays', 3)\n",
      "('skip', 3)\n",
      "('baby', 3)\n",
      "('code', 3)\n",
      "('skelos', 3)\n",
      "('did', 3)\n",
      "('nbc', 3)\n",
      "('truckers', 3)\n",
      "('public', 3)\n",
      "('action', 3)\n",
      "('shootings', 3)\n",
      "('scandal', 3)\n",
      "('insider', 3)\n",
      "('music', 3)\n",
      "('spike', 3)\n",
      "('door', 3)\n",
      "('science', 3)\n",
      "('please', 3)\n",
      "('clothing', 3)\n",
      "('seacrest', 3)\n",
      "('how', 3)\n",
      "('nyc', 3)\n",
      "('he', 3)\n",
      "('fifa', 3)\n",
      "('exclusive', 3)\n",
      "('over', 3)\n",
      "('designer', 3)\n",
      "('its', 3)\n",
      "('rubio', 3)\n",
      "('good', 3)\n",
      "('now', 3)\n",
      "('events', 3)\n",
      "('store', 3)\n",
      "('development', 3)\n",
      "('house', 3)\n",
      "('teams', 3)\n",
      "('living', 3)\n",
      "('content', 3)\n",
      "('deals', 3)\n",
      "('keep', 3)\n",
      "('features', 3)\n",
      "('apps', 3)\n",
      "('privacy', 3)\n",
      "('way', 3)\n",
      "('lee\\xe2\\x80\\x99s', 3)\n",
      "('theater', 3)\n",
      "('rampage', 3)\n",
      "('won\\xe2\\x80\\x99t', 3)\n",
      "('collaboration', 3)\n",
      "('who', 3)\n",
      "('most', 3)\n",
      "('courtesy', 3)\n",
      "('adopt', 3)\n",
      "('title', 3)\n",
      "('where', 3)\n",
      "('genderneutral', 3)\n",
      "('david', 3)\n",
      "('kitchen', 3)\n",
      "('shopping', 3)\n",
      "('easy', 3)\n",
      "('sales', 3)\n",
      "('editorial', 3)\n",
      "('site', 3)\n",
      "('kindle', 3)\n",
      "('\\xe2\\x80\\x98chiraq\\xe2\\x80\\x99', 3)\n",
      "('\\xe2\\x80\\x98mx\\xe2\\x80\\x99', 3)\n",
      "('money', 3)\n",
      "('loading', 3)\n",
      "('ny', 3)\n",
      "('book', 3)\n",
      "('private', 3)\n",
      "('right', 3)\n",
      "('some', 3)\n",
      "('back', 3)\n",
      "('shoes', 3)\n",
      "('sections', 3)\n",
      "('line', 3)\n",
      "('made', 3)\n",
      "('politics', 3)\n",
      "('know', 3)\n",
      "('nytimescom', 3)\n",
      "('battle', 2)\n",
      "('pledged', 2)\n",
      "('retire', 2)\n",
      "('automobiles', 2)\n",
      "('difference', 2)\n",
      "('school', 2)\n",
      "('ryan', 2)\n",
      "('race', 2)\n",
      "('phones', 2)\n",
      "('rate', 2)\n",
      "('lawyer', 2)\n",
      "('multimedia', 2)\n",
      "('supporter', 2)\n",
      "('inyour', 2)\n",
      "('suspect', 2)\n",
      "('international', 2)\n",
      "('seeks', 2)\n",
      "('terrorism', 2)\n",
      "('friday', 2)\n",
      "('built', 2)\n",
      "('musical', 2)\n",
      "('explore', 2)\n",
      "('killings', 2)\n",
      "('web', 2)\n",
      "('legend', 2)\n",
      "('desktop', 2)\n",
      "('study', 2)\n",
      "('trial', 2)\n",
      "('gear', 2)\n",
      "('1248', 2)\n",
      "('had', 2)\n",
      "('options', 2)\n",
      "('cardamazoncom', 2)\n",
      "('mamet\\xe2\\x80\\x99s', 2)\n",
      "('cowardly', 2)\n",
      "('app', 2)\n",
      "('fbi', 2)\n",
      "('fed', 2)\n",
      "('live', 2)\n",
      "('journalists', 2)\n",
      "('pricing', 2)\n",
      "('accessories', 2)\n",
      "('cards', 2)\n",
      "('91', 2)\n",
      "('account', 2)\n",
      "('include', 2)\n",
      "('work', 2)\n",
      "('suspects\\xe2\\x80\\x99', 2)\n",
      "('mr', 2)\n",
      "('growing', 2)\n",
      "('evangelicals', 2)\n",
      "('computers', 2)\n",
      "('indie', 2)\n",
      "('soup', 2)\n",
      "('marco', 2)\n",
      "('tab', 2)\n",
      "('rye', 2)\n",
      "('enterprise', 2)\n",
      "('nyt', 2)\n",
      "('sunday', 2)\n",
      "('speaks', 2)\n",
      "('economy', 2)\n",
      "('plans', 2)\n",
      "('wrong', 2)\n",
      "('brands', 2)\n",
      "('man', 2)\n",
      "('hanukkah', 2)\n",
      "('road', 2)\n",
      "('looking', 2)\n",
      "('talk', 2)\n",
      "('wine', 2)\n",
      "('feedback', 2)\n",
      "('scott', 2)\n",
      "('cruise', 2)\n",
      "('better', 2)\n",
      "('policy', 2)\n",
      "('amazonsell', 2)\n",
      "('texas', 2)\n",
      "('toys', 2)\n",
      "('emerald', 2)\n",
      "('killed', 2)\n",
      "('articles', 2)\n",
      "('countries', 2)\n",
      "('arrested', 2)\n",
      "('refresh', 2)\n",
      "('out', 2)\n",
      "('related', 2)\n",
      "('ring', 2)\n",
      "('reload', 2)\n",
      "('islamist', 2)\n",
      "('d\\xe2\\x80\\x99amato', 2)\n",
      "('landlord', 2)\n",
      "('state', 2)\n",
      "('credit', 2)\n",
      "('brooks', 2)\n",
      "('obituaries', 2)\n",
      "('california', 2)\n",
      "('applications', 2)\n",
      "('listings', 2)\n",
      "('american', 2)\n",
      "('pilots', 2)\n",
      "('insist', 2)\n",
      "('vote', 2)\n",
      "('story', 2)\n",
      "('service', 2)\n",
      "('shooting', 2)\n",
      "('upshot', 2)\n",
      "('white', 2)\n",
      "('behind', 2)\n",
      "('jordan', 2)\n",
      "('copy', 2)\n",
      "('than', 2)\n",
      "('ben', 2)\n",
      "('were', 2)\n",
      "('design', 2)\n",
      "('mogul', 2)\n",
      "('have', 2)\n",
      "('any', 2)\n",
      "('viewed', 2)\n",
      "('ratings', 2)\n",
      "('discounts', 2)\n",
      "('also', 2)\n",
      "('carson\\xe2\\x80\\x99s', 2)\n",
      "('luxury', 2)\n",
      "('moscow', 2)\n",
      "('play', 2)\n",
      "('vivian', 2)\n",
      "('mobile', 2)\n",
      "('m', 2)\n",
      "('hungry', 2)\n",
      "('tech', 2)\n",
      "('amazoncom', 2)\n",
      "('chowder', 2)\n",
      "('playbook', 2)\n",
      "('longer', 2)\n",
      "('tape', 2)\n",
      "('nachman', 2)\n",
      "('storage', 2)\n",
      "('10', 2)\n",
      "('photography', 2)\n",
      "('stop', 2)\n",
      "('television', 2)\n",
      "('employers', 2)\n",
      "('westchester', 2)\n",
      "('gray', 2)\n",
      "('bestselling', 2)\n",
      "('covering', 2)\n",
      "('fixed', 2)\n",
      "('todayrsquos', 2)\n",
      "('48', 2)\n",
      "('view', 2)\n",
      "('sewing', 2)\n",
      "('art', 2)\n",
      "('our', 2)\n",
      "('we', 2)\n",
      "('australia', 2)\n",
      "('college', 2)\n",
      "('project', 2)\n",
      "('said', 2)\n",
      "('ways', 2)\n",
      "('misogynist', 2)\n",
      "('\\xe2\\x80\\x98china', 2)\n",
      "('disgruntled', 2)\n",
      "('iberianinspired', 2)\n",
      "('men', 2)\n",
      "('creating', 2)\n",
      "('ask', 2)\n",
      "('latkes', 2)\n",
      "('climate', 2)\n",
      "('signed', 2)\n",
      "('officer', 2)\n",
      "('hummus', 2)\n",
      "('senator', 2)\n",
      "('baltimore', 2)\n",
      "('america\\xe2\\x80\\x99s', 2)\n",
      "('session', 2)\n",
      "('reasons', 2)\n",
      "('sweet', 2)\n",
      "('allegiance', 2)\n",
      "('100', 2)\n",
      "('strong', 2)\n",
      "('asks', 2)\n",
      "('source', 2)\n",
      "('window', 2)\n",
      "('treat', 2)\n",
      "('contribute', 2)\n",
      "('worker', 2)\n",
      "('kids', 2)\n",
      "('former', 2)\n",
      "('homes', 2)\n",
      "('look', 2)\n",
      "('gifts', 2)\n",
      "('cell', 2)\n",
      "('media\\xe2\\x80\\x99s', 2)\n",
      "('denial', 2)\n",
      "('doll\\xe2\\x80\\x99', 2)\n",
      "('murderer\\xe2\\x80\\x99s', 2)\n",
      "('roland', 2)\n",
      "('reminder', 2)\n",
      "('weiland', 2)\n",
      "('center', 2)\n",
      "('pacino', 2)\n",
      "('changes', 2)\n",
      "('well', 2)\n",
      "('contact', 2)\n",
      "('relief', 2)\n",
      "('corporate', 2)\n",
      "('left', 2)\n",
      "('executive', 2)\n",
      "('yet', 2)\n",
      "('thinking', 2)\n",
      "('workers', 2)\n",
      "('blog', 2)\n",
      "('sullivan', 2)\n",
      "('dance', 2)\n",
      "('win', 2)\n",
      "('has', 2)\n",
      "('sicily', 2)\n",
      "('matters', 2)\n",
      "('amp', 2)\n",
      "('grim', 2)\n",
      "('like', 2)\n",
      "('65', 2)\n",
      "('learning', 2)\n",
      "('people', 2)\n",
      "('motive', 2)\n",
      "('donald', 2)\n",
      "('another', 2)\n",
      "('pet', 2)\n",
      "('delaware', 2)\n",
      "('legal', 2)\n",
      "('temple', 2)\n",
      "('payment', 2)\n",
      "('use', 2)\n",
      "('raise', 2)\n",
      "('hearing', 2)\n",
      "('faith', 2)\n",
      "('stone', 2)\n",
      "('rare', 2)\n",
      "('act', 2)\n",
      "('block', 2)\n",
      "('orders', 2)\n",
      "('puzzle', 2)\n",
      "('down', 2)\n",
      "('homeless', 2)\n",
      "('gift', 2)\n",
      "('racist', 2)\n",
      "('editor', 2)\n",
      "('series', 2)\n",
      "('libel', 2)\n",
      "('singer', 2)\n",
      "('delivery', 2)\n",
      "('podcast', 2)\n",
      "('inside', 2)\n",
      "('official', 2)\n",
      "('economic', 2)\n",
      "('electronics', 2)\n",
      "('v', 2)\n",
      "('sale', 2)\n",
      "('ship', 2)\n",
      "('inc', 2)\n",
      "('when', 2)\n",
      "('green', 2)\n",
      "('why', 2)\n",
      "('kansas', 2)\n",
      "('scores', 2)\n",
      "('photo', 1)\n",
      "('gt', 1)\n",
      "('accountyour', 1)\n",
      "('cofounded', 1)\n",
      "('ganz', 1)\n",
      "('suburban', 1)\n",
      "('child', 1)\n",
      "('month', 1)\n",
      "('protest', 1)\n",
      "('groceries', 1)\n",
      "('gang', 1)\n",
      "('aides', 1)\n",
      "('papervideo', 1)\n",
      "('appetite', 1)\n",
      "('religious', 1)\n",
      "('issues', 1)\n",
      "('carpet', 1)\n",
      "('whose', 1)\n",
      "('apartment', 1)\n",
      "('essentials', 1)\n",
      "('paris', 1)\n",
      "('journeys', 1)\n",
      "('editors', 1)\n",
      "('thursday', 1)\n",
      "('344', 1)\n",
      "('0', 1)\n",
      "('videos', 1)\n",
      "('macfarquhar', 1)\n",
      "('innis', 1)\n",
      "('must', 1)\n",
      "('pledges', 1)\n",
      "('supreme', 1)\n",
      "('adviser', 1)\n",
      "('updated', 1)\n",
      "('garden', 1)\n",
      "('hannah', 1)\n",
      "('automotive', 1)\n",
      "('rise', 1)\n",
      "('tent', 1)\n",
      "('sellers', 1)\n",
      "('deviceshelp', 1)\n",
      "('facebook', 1)\n",
      "('additional', 1)\n",
      "('suggests', 1)\n",
      "('instruments', 1)\n",
      "('philanthropic', 1)\n",
      "('died', 1)\n",
      "('timesvideo', 1)\n",
      "('treating', 1)\n",
      "('productsselfpublish', 1)\n",
      "('zappos', 1)\n",
      "('mercurial', 1)\n",
      "('michael', 1)\n",
      "('solved', 1)\n",
      "('spurred', 1)\n",
      "('highway', 1)\n",
      "('car', 1)\n",
      "('depository', 1)\n",
      "('settings', 1)\n",
      "('caryn', 1)\n",
      "('enjoy', 1)\n",
      "('uscareersabout', 1)\n",
      "('team', 1)\n",
      "('reims', 1)\n",
      "('skin', 1)\n",
      "('openbox', 1)\n",
      "('direct', 1)\n",
      "('cyber', 1)\n",
      "('1127', 1)\n",
      "('past', 1)\n",
      "('cost', 1)\n",
      "('governor', 1)\n",
      "('pass', 1)\n",
      "('air', 1)\n",
      "('makers', 1)\n",
      "('victor', 1)\n",
      "('index', 1)\n",
      "('richard', 1)\n",
      "('section', 1)\n",
      "('seven', 1)\n",
      "('while', 1)\n",
      "('week\\xe2\\x80\\x99s', 1)\n",
      "('current', 1)\n",
      "('version', 1)\n",
      "('goes', 1)\n",
      "('toll', 1)\n",
      "('net', 1)\n",
      "('appeal', 1)\n",
      "('wwwamazoncomaccess', 1)\n",
      "('createspace', 1)\n",
      "('notredame', 1)\n",
      "('richest', 1)\n",
      "('affiliates', 1)\n",
      "('hundreds', 1)\n",
      "('china', 1)\n",
      "('6pm', 1)\n",
      "('investigating', 1)\n",
      "('path', 1)\n",
      "('november', 1)\n",
      "('longdistance', 1)\n",
      "('106', 1)\n",
      "('change', 1)\n",
      "('landmarks', 1)\n",
      "('bible', 1)\n",
      "('governor\\xe2\\x80\\x99s', 1)\n",
      "('luggage', 1)\n",
      "('shift', 1)\n",
      "('audiobook', 1)\n",
      "('experience', 1)\n",
      "('leaving', 1)\n",
      "('recently', 1)\n",
      "('\\xe2\\x80\\x98invisible', 1)\n",
      "('products', 1)\n",
      "('security', 1)\n",
      "('navigation', 1)\n",
      "('vinyl', 1)\n",
      "('useful', 1)\n",
      "('wearables', 1)\n",
      "('ground', 1)\n",
      "('manage', 1)\n",
      "('integrations', 1)\n",
      "('commandments', 1)\n",
      "('minnesota', 1)\n",
      "('put', 1)\n",
      "('primereturns', 1)\n",
      "('you\\xe2\\x80\\x99re', 1)\n",
      "('p\\xc3\\x89rezpe\\xc3\\x91a', 1)\n",
      "('appliances', 1)\n",
      "('stern', 1)\n",
      "('classifieds', 1)\n",
      "('hammer\\xe2\\x80\\x99', 1)\n",
      "('market', 1)\n",
      "('nursing', 1)\n",
      "('seamless', 1)\n",
      "('takedown', 1)\n",
      "('deploy\\xe2\\x80\\x94all', 1)\n",
      "('resigns', 1)\n",
      "('7mo', 1)\n",
      "('wordplay', 1)\n",
      "('organization', 1)\n",
      "('mysterious', 1)\n",
      "('candidates', 1)\n",
      "('care', 1)\n",
      "('ads\\xc2\\xa9', 1)\n",
      "('amazonglobal', 1)\n",
      "('native', 1)\n",
      "('flat', 1)\n",
      "('shanice', 1)\n",
      "('started', 1)\n",
      "('oscar', 1)\n",
      "('company', 1)\n",
      "('musician', 1)\n",
      "('benchmark', 1)\n",
      "('improve', 1)\n",
      "('lore', 1)\n",
      "('train', 1)\n",
      "('jungleecom', 1)\n",
      "('testifies', 1)\n",
      "('effort', 1)\n",
      "('women', 1)\n",
      "('animals', 1)\n",
      "('skill\\xe2\\x80\\x99', 1)\n",
      "('1996', 1)\n",
      "('challenge', 1)\n",
      "('request', 1)\n",
      "('cat', 1)\n",
      "('reviews', 1)\n",
      "('nation\\xe2\\x80\\x99s', 1)\n",
      "('condominium', 1)\n",
      "('can', 1)\n",
      "('dewalt', 1)\n",
      "('my', 1)\n",
      "('itaposs', 1)\n",
      "('amazonbecome', 1)\n",
      "('control', 1)\n",
      "('heart', 1)\n",
      "('kenneth', 1)\n",
      "('activities', 1)\n",
      "('december', 1)\n",
      "('subsidies', 1)\n",
      "('newsletters', 1)\n",
      "('india', 1)\n",
      "('hauser', 1)\n",
      "('states', 1)\n",
      "('currency', 1)\n",
      "('usbecome', 1)\n",
      "('accounttryprimeyourlistscart', 1)\n",
      "('chic', 1)\n",
      "('audible', 1)\n",
      "('aging', 1)\n",
      "('united', 1)\n",
      "('end', 1)\n",
      "('winter', 1)\n",
      "('agree', 1)\n",
      "('off', 1)\n",
      "('writers', 1)\n",
      "('answer', 1)\n",
      "('community', 1)\n",
      "('map', 1)\n",
      "('product', 1)\n",
      "('de', 1)\n",
      "('servers', 1)\n",
      "('may', 1)\n",
      "('watch', 1)\n",
      "('earlier', 1)\n",
      "('spot', 1)\n",
      "('lowercase', 1)\n",
      "('roads', 1)\n",
      "('scalable', 1)\n",
      "('islamic', 1)\n",
      "('1053', 1)\n",
      "('samesex', 1)\n",
      "('court', 1)\n",
      "('lifting', 1)\n",
      "('status', 1)\n",
      "('acx', 1)\n",
      "('branches', 1)\n",
      "('third', 1)\n",
      "('gollum', 1)\n",
      "('life', 1)\n",
      "('jail', 1)\n",
      "('crafts', 1)\n",
      "('\\xe2\\x80\\x98star', 1)\n",
      "('breaking', 1)\n",
      "('schwartz', 1)\n",
      "('move', 1)\n",
      "('find', 1)\n",
      "('thousands', 1)\n",
      "('131', 1)\n",
      "('paper', 1)\n",
      "('headings', 1)\n",
      "('blocked', 1)\n",
      "('what\\xe2\\x80\\x99s', 1)\n",
      "('25', 1)\n",
      "('group', 1)\n",
      "('internationally', 1)\n",
      "('duplex', 1)\n",
      "('jim', 1)\n",
      "('warehouse', 1)\n",
      "('emails', 1)\n",
      "('edits', 1)\n",
      "('offers', 1)\n",
      "('systems', 1)\n",
      "('pakistan\\xe2\\x80\\x99s', 1)\n",
      "('puerto', 1)\n",
      "('schmidt', 1)\n",
      "('productsamazoncom', 1)\n",
      "('schools', 1)\n",
      "('largest', 1)\n",
      "('bought', 1)\n",
      "('multimediaphotos', 1)\n",
      "('band', 1)\n",
      "('own', 1)\n",
      "('grows', 1)\n",
      "('term', 1)\n",
      "('holiday', 1)\n",
      "('artsbeat', 1)\n",
      "('always', 1)\n",
      "('shenanigans', 1)\n",
      "('follow', 1)\n",
      "('rock', 1)\n",
      "('minimalism', 1)\n",
      "('found', 1)\n",
      "('entirely', 1)\n",
      "('goodreads', 1)\n",
      "('went', 1)\n",
      "('investigators', 1)\n",
      "('square', 1)\n",
      "('neil', 1)\n",
      "('female', 1)\n",
      "('reduce', 1)\n",
      "('tighten', 1)\n",
      "('faithdriven', 1)\n",
      "('year', 1)\n",
      "('repository', 1)\n",
      "('85', 1)\n",
      "('network', 1)\n",
      "('blacks', 1)\n",
      "('robert', 1)\n",
      "('since', 1)\n",
      "('\\xc2\\xb7', 1)\n",
      "('critics', 1)\n",
      "('daniel', 1)\n",
      "('longtime', 1)\n",
      "('7', 1)\n",
      "('internet', 1)\n",
      "('print', 1)\n",
      "('211000', 1)\n",
      "('shortly', 1)\n",
      "('calif', 1)\n",
      "('red', 1)\n",
      "('shows', 1)\n",
      "('website', 1)\n",
      "('love', 1)\n",
      "('frank', 1)\n",
      "('million', 1)\n",
      "('gwftgrdesktopherokindleb', 1)\n",
      "('pumping', 1)\n",
      "('quite', 1)\n",
      "('zuckerberg', 1)\n",
      "('extraordinary', 1)\n",
      "('marino', 1)\n",
      "('x', 1)\n",
      "('mimi', 1)\n",
      "('region', 1)\n",
      "('card', 1)\n",
      "('gwftgrdesktopheroprime', 1)\n",
      "('training', 1)\n",
      "('comixology', 1)\n",
      "('g', 1)\n",
      "('starts', 1)\n",
      "('could', 1)\n",
      "('florida', 1)\n",
      "('membership', 1)\n",
      "('turn', 1)\n",
      "('notebook', 1)\n",
      "('place', 1)\n",
      "('w', 1)\n",
      "('signature', 1)\n",
      "('corrections', 1)\n",
      "('turf', 1)\n",
      "('austin', 1)\n",
      "('think', 1)\n",
      "('cheese', 1)\n",
      "('major', 1)\n",
      "('industrial', 1)\n",
      "('analytics', 1)\n",
      "('arsenal', 1)\n",
      "('britain8217s', 1)\n",
      "('opec', 1)\n",
      "('discover', 1)\n",
      "('americans', 1)\n",
      "('normality', 1)\n",
      "('backyard', 1)\n",
      "('traveler', 1)\n",
      "('message', 1)\n",
      "('diaperscom', 1)\n",
      "('grocery', 1)\n",
      "('millions', 1)\n",
      "('rented', 1)\n",
      "('ancient', 1)\n",
      "('heads', 1)\n",
      "('gourmet', 1)\n",
      "('commit', 1)\n",
      "('cambodians', 1)\n",
      "('ussell', 1)\n",
      "('download', 1)\n",
      "('attack', 1)\n",
      "('listed', 1)\n",
      "('clicking', 1)\n",
      "('bits', 1)\n",
      "('williams', 1)\n",
      "('guarantee', 1)\n",
      "('urban', 1)\n",
      "('weddings', 1)\n",
      "('pointscredit', 1)\n",
      "('hun', 1)\n",
      "('hotel', 1)\n",
      "('abebooks', 1)\n",
      "('took', 1)\n",
      "('yoyocom', 1)\n",
      "('least', 1)\n",
      "('lengthier', 1)\n",
      "('thai', 1)\n",
      "('convinced', 1)\n",
      "('wars\\xe2\\x80\\x99', 1)\n",
      "('mercy', 1)\n",
      "('colleagues', 1)\n",
      "('cracks', 1)\n",
      "('14', 1)\n",
      "('emailedmost', 1)\n",
      "('myhabit', 1)\n",
      "('likely', 1)\n",
      "('defends', 1)\n",
      "('matter', 1)\n",
      "('greg', 1)\n",
      "('boehler', 1)\n",
      "('friend', 1)\n",
      "('polishing', 1)\n",
      "('dane', 1)\n",
      "('browser', 1)\n",
      "('woot', 1)\n",
      "('terrorism\\xe2\\x80\\x9d', 1)\n",
      "('palace', 1)\n",
      "('remained', 1)\n",
      "('lines', 1)\n",
      "('improbability', 1)\n",
      "('reader', 1)\n",
      "('hylton\\xe2\\x80\\x99s', 1)\n",
      "('voices', 1)\n",
      "('say', 1)\n",
      "('rewards', 1)\n",
      "('imdb', 1)\n",
      "('rent', 1)\n",
      "('close', 1)\n",
      "('seem', 1)\n",
      "('seek', 1)\n",
      "('alfonse', 1)\n",
      "('sell', 1)\n",
      "('depict', 1)\n",
      "('friday\\xe2\\x80\\x99s', 1)\n",
      "('agency', 1)\n",
      "('rashbaum', 1)\n",
      "('krugman', 1)\n",
      "('makeover', 1)\n",
      "('concerns', 1)\n",
      "('noticeinterestbased', 1)\n",
      "('so', 1)\n",
      "('worldwide', 1)\n",
      "('added', 1)\n",
      "('marketplaceamazon', 1)\n",
      "('quote', 1)\n",
      "('kean', 1)\n",
      "('freddie', 1)\n",
      "('vengeance', 1)\n",
      "('sponsored', 1)\n",
      "('plan', 1)\n",
      "('letter', 1)\n",
      "('claims', 1)\n",
      "('allamazon', 1)\n",
      "('prestige', 1)\n",
      "('pages', 1)\n",
      "('unsparing', 1)\n",
      "('michelle', 1)\n",
      "('cuban', 1)\n",
      "('1040', 1)\n",
      "('clear', 1)\n",
      "('tooth', 1)\n",
      "('actionable', 1)\n",
      "('vinemarketcom', 1)\n",
      "('patio', 1)\n",
      "('clearing', 1)\n",
      "('communication', 1)\n",
      "('occasion', 1)\n",
      "('came', 1)\n",
      "('laws', 1)\n",
      "('relationsamazon', 1)\n",
      "('amazoncomtodays', 1)\n",
      "('show', 1)\n",
      "('text', 1)\n",
      "('queen', 1)\n",
      "('celebrities', 1)\n",
      "('contemporary', 1)\n",
      "('russian', 1)\n",
      "('outdoor', 1)\n",
      "('fino', 1)\n",
      "('cds', 1)\n",
      "('dorothy', 1)\n",
      "('fear', 1)\n",
      "('fine', 1)\n",
      "('caper', 1)\n",
      "('viewedrecommended', 1)\n",
      "('cameras', 1)\n",
      "('upgrade', 1)\n",
      "('160160160girls', 1)\n",
      "('office', 1)\n",
      "('menu', 1)\n",
      "('basel', 1)\n",
      "('outside', 1)\n",
      "('controls', 1)\n",
      "('mens', 1)\n",
      "('rico', 1)\n",
      "('score', 1)\n",
      "('inherited', 1)\n",
      "('integrate', 1)\n",
      "('marriage', 1)\n",
      "('watching', 1)\n",
      "('population', 1)\n",
      "('local', 1)\n",
      "('mortality', 1)\n",
      "('dvds', 1)\n",
      "('familiar', 1)\n",
      "('honda', 1)\n",
      "('observatory', 1)\n",
      "('hid', 1)\n",
      "('frictionless', 1)\n",
      "('invited', 1)\n",
      "('leases', 1)\n",
      "('falling', 1)\n",
      "('distraction', 1)\n",
      "('afterschoolcom', 1)\n",
      "('beautybarcom', 1)\n",
      "('textbooks', 1)\n",
      "('hinges', 1)\n",
      "('rothschild', 1)\n",
      "('businesssell', 1)\n",
      "('affluent', 1)\n",
      "('comics', 1)\n",
      "('republicans\\xe2\\x80\\x99', 1)\n",
      "('stuff', 1)\n",
      "('explorer', 1)\n",
      "('africa\\xe2\\x80\\x99s', 1)\n",
      "('recommendations', 1)\n",
      "('palace\\xe2\\x80\\x99s', 1)\n",
      "('tightening', 1)\n",
      "('questions', 1)\n",
      "('fair', 1)\n",
      "('problem', 1)\n",
      "('simple', 1)\n",
      "('humans', 1)\n",
      "('sex', 1)\n",
      "('edition', 1)\n",
      "('officials', 1)\n",
      "('migration', 1)\n",
      "('sen', 1)\n",
      "('cardssellhelp', 1)\n",
      "('suspects', 1)\n",
      "('threats', 1)\n",
      "('mortgage', 1)\n",
      "('don\\xe2\\x80\\x99t', 1)\n",
      "('artworld', 1)\n",
      "('away', 1)\n",
      "('familiarity', 1)\n",
      "('kind', 1)\n",
      "('tolls', 1)\n",
      "('3', 1)\n",
      "('bruni', 1)\n",
      "('crisis', 1)\n",
      "('vocals', 1)\n",
      "('conditions', 1)\n",
      "('corruption', 1)\n",
      "('warrior', 1)\n",
      "('ends', 1)\n",
      "('collectibles', 1)\n",
      "('screen', 1)\n",
      "('monarchy', 1)\n",
      "('handpicked', 1)\n",
      "('outfit', 1)\n",
      "('kids\\xe2\\x80\\x99', 1)\n",
      "('160160160men', 1)\n",
      "('accountsign', 1)\n",
      "('opposition', 1)\n",
      "('opinionator', 1)\n",
      "('interface', 1)\n",
      "('debt', 1)\n",
      "('lawn', 1)\n",
      "('accident', 1)\n",
      "('accused', 1)\n",
      "('wagcom', 1)\n",
      "('many', 1)\n",
      "('taking', 1)\n",
      "('samaritan', 1)\n",
      "('casacom', 1)\n",
      "('quiet', 1)\n",
      "('against', 1)\n",
      "('tour', 1)\n",
      "('supplies', 1)\n",
      "('160160160boys', 1)\n",
      "('bronx', 1)\n",
      "('share', 1)\n",
      "('bond', 1)\n",
      "('affiliateadvertise', 1)\n",
      "('useprivacy', 1)\n",
      "('comment', 1)\n",
      "('2295', 1)\n",
      "('60', 1)\n",
      "('likes', 1)\n",
      "('genes', 1)\n",
      "('approval', 1)\n",
      "('townhouse', 1)\n",
      "('improvement', 1)\n",
      "('math', 1)\n",
      "('turkey', 1)\n",
      "('poem', 1)\n",
      "('21stcentury', 1)\n",
      "('create', 1)\n",
      "('sara', 1)\n",
      "('conflicts', 1)\n",
      "('been', 1)\n",
      "('mark', 1)\n",
      "('gopro', 1)\n",
      "('much', 1)\n",
      "('complicated', 1)\n",
      "('interest', 1)\n",
      "('parents', 1)\n",
      "('meeting', 1)\n",
      "('topics', 1)\n",
      "('idol', 1)\n",
      "('wants', 1)\n",
      "('mike', 1)\n",
      "('1214', 1)\n",
      "('gwftgrdesktopheropiv', 1)\n",
      "('\\xe2\\x80\\x9cas', 1)\n",
      "('collaborators', 1)\n",
      "('al', 1)\n",
      "('lives', 1)\n",
      "('suspension', 1)\n",
      "('quick', 1)\n",
      "('despite', 1)\n",
      "('pilot', 1)\n",
      "('guarantees', 1)\n",
      "('lookcom', 1)\n",
      "('tip', 1)\n",
      "('irate', 1)\n",
      "('choices', 1)\n",
      "('lagrange', 1)\n",
      "('near', 1)\n",
      "('moratorium', 1)\n",
      "('amazoninvestor', 1)\n",
      "('involved', 1)\n",
      "('aid', 1)\n",
      "('k', 1)\n",
      "('theres', 1)\n",
      "('penthouse', 1)\n",
      "('secluded', 1)\n",
      "('likable', 1)\n",
      "('uganda', 1)\n",
      "('voters', 1)\n",
      "('helped', 1)\n",
      "('player', 1)\n",
      "('vs', 1)\n",
      "('malls', 1)\n",
      "('personal', 1)\n",
      "('vw', 1)\n",
      "('facade', 1)\n",
      "('smartwatches', 1)\n",
      "('converterlet', 1)\n",
      "('technology', 1)\n",
      "('audi', 1)\n",
      "('lengthy', 1)\n",
      "('doctor', 1)\n",
      "('devicesmake', 1)\n",
      "('barnes', 1)\n",
      "('abbott\\xe2\\x80\\x99s', 1)\n",
      "('replacementsmanage', 1)\n",
      "('access', 1)\n",
      "('pros', 1)\n",
      "('1154', 1)\n",
      "('9', 1)\n",
      "('youyour', 1)\n",
      "('powell', 1)\n",
      "('twoday', 1)\n",
      "('noble', 1)\n",
      "('barbed', 1)\n",
      "('oil', 1)\n",
      "('knitting', 1)\n",
      "('together', 1)\n",
      "('2015today\\xe2\\x80\\x99s', 1)\n",
      "('evil', 1)\n",
      "('driven', 1)\n",
      "('want', 1)\n",
      "('user', 1)\n",
      "('characters', 1)\n",
      "('robotic', 1)\n",
      "('robust', 1)\n",
      "('soapcom', 1)\n",
      "('recent', 1)\n",
      "('celtic', 1)\n",
      "('supports', 1)\n",
      "('renters', 1)\n",
      "('gwftgrdesktopheroh', 1)\n",
      "('charges', 1)\n",
      "('weapon', 1)\n",
      "('fever', 1)\n",
      "('mortgages', 1)\n",
      "('revising', 1)\n",
      "('model', 1)\n",
      "('audio', 1)\n",
      "('scientists', 1)\n",
      "('send', 1)\n",
      "('214', 1)\n",
      "('215', 1)\n",
      "('just', 1)\n",
      "('unemployment', 1)\n",
      "('19962015', 1)\n",
      "('yee', 1)\n",
      "('terrorist', 1)\n",
      "('shopbop', 1)\n",
      "('select', 1)\n",
      "('circling', 1)\n",
      "('human', 1)\n",
      "('handmade', 1)\n",
      "('happiness', 1)\n",
      "('previous', 1)\n",
      "('note', 1)\n",
      "('character', 1)\n",
      "('day', 1)\n",
      "('lets', 1)\n",
      "('extends', 1)\n",
      "('4', 1)\n",
      "('input', 1)\n",
      "('ski', 1)\n",
      "('limp', 1)\n",
      "('details', 1)\n",
      "('thread\\xe2\\x80\\x99', 1)\n",
      "('editorials', 1)\n",
      "('government', 1)\n",
      "('vendorrsaquosee', 1)\n",
      "('docks', 1)\n",
      "('couple', 1)\n",
      "('nbspcomments', 1)\n",
      "('unlimited', 1)\n",
      "('mealdelivery', 1)\n",
      "('dealsgift', 1)\n",
      "('five', 1)\n",
      "('messengers', 1)\n",
      "('background', 1)\n",
      "('donor', 1)\n",
      "('judge', 1)\n",
      "('d', 1)\n",
      "('necessary', 1)\n",
      "('christine', 1)\n",
      "('miami', 1)\n",
      "('patrick', 1)\n",
      "('future', 1)\n",
      "('hunt', 1)\n",
      "('kremlin', 1)\n",
      "('ornately', 1)\n",
      "('api', 1)\n",
      "('payments', 1)\n",
      "('yorker', 1)\n",
      "('vibrant', 1)\n",
      "('you\\xe2\\x80\\x99ll', 1)\n",
      "('become', 1)\n",
      "('\\xe4\\xb8\\xad\\xe6\\x96\\x87', 1)\n",
      "('works', 1)\n",
      "('page', 1)\n",
      "('soccer', 1)\n",
      "('dean', 1)\n",
      "('feast', 1)\n",
      "('columnists', 1)\n",
      "('dead', 1)\n",
      "('productions', 1)\n",
      "('fabric', 1)\n",
      "('images', 1)\n",
      "('advertise', 1)\n",
      "('classes', 1)\n",
      "('nicaragua', 1)\n",
      "('numeral', 1)\n",
      "('delivered', 1)\n",
      "('jeremy', 1)\n",
      "('jewelry', 1)\n",
      "('windows', 1)\n",
      "('1250000', 1)\n",
      "('colonial', 1)\n",
      "('fox', 1)\n",
      "('seller', 1)\n",
      "('contributing', 1)\n",
      "('cloud', 1)\n",
      "('gwftgrdesktopherokindlea', 1)\n",
      "('lineshop', 1)\n",
      "('swartz', 1)\n",
      "('either', 1)\n",
      "('aesthete\\xe2\\x80\\x99s', 1)\n",
      "('object', 1)\n",
      "('medieval', 1)\n",
      "('communicate', 1)\n",
      "('addicted', 1)\n",
      "('discussion', 1)\n",
      "('eye', 1)\n",
      "('loans', 1)\n",
      "('properties', 1)\n",
      "('operating', 1)\n",
      "('puts', 1)\n",
      "('island', 1)\n",
      "('craft', 1)\n",
      "('violence', 1)\n",
      "('brooklyn', 1)\n",
      "('shipping', 1)\n",
      "('hot', 1)\n",
      "('dpreview', 1)\n",
      "('rosen', 1)\n",
      "('collaborative', 1)\n",
      "('occasionally', 1)\n",
      "('eight', 1)\n",
      "('seamless\\xe2\\x80\\x99s', 1)\n",
      "('os', 1)\n",
      "('celebrations', 1)\n",
      "('letters', 1)\n",
      "('bundles', 1)\n",
      "('son', 1)\n",
      "('neutrality', 1)\n",
      "('accounts', 1)\n",
      "('selected', 1)\n",
      "('contributor', 1)\n",
      "('lesson', 1)\n",
      "('federal', 1)\n",
      "('often', 1)\n",
      "('bydepartment', 1)\n",
      "('east', 1)\n",
      "('van', 1)\n",
      "('log', 1)\n",
      "('her', 1)\n",
      "('little', 1)\n",
      "('housing', 1)\n",
      "('world\\xe2\\x80\\x99s', 1)\n",
      "('ramzy', 1)\n",
      "('cultured', 1)\n",
      "('peters', 1)\n",
      "('loscutoff', 1)\n",
      "('start', 1)\n",
      "('lot', 1)\n",
      "('biggest', 1)\n",
      "('\\xe2\\x80\\x98snowflakes\\xe2\\x80\\x99', 1)\n",
      "('computing', 1)\n",
      "('gwftgrdesktopherosoftlines', 1)\n",
      "('happy', 1)\n",
      "('alexa', 1)\n",
      "('year\\xe2\\x80\\x99s', 1)\n",
      "('something', 1)\n",
      "('great', 1)\n",
      "('160160160baby', 1)\n",
      "('pierre', 1)\n",
      "('sherry', 1)\n",
      "('link', 1)\n",
      "('he\\xe2\\x80\\x99s', 1)\n",
      "('cottage', 1)\n",
      "('222', 1)\n",
      "('\\xe2\\x80\\x94', 1)\n",
      "('perfect', 1)\n",
      "('isis', 1)\n",
      "('staged', 1)\n",
      "('cams', 1)\n",
      "('customers', 1)\n",
      "('emissions', 1)\n",
      "('\\xe2\\x80\\x98steel', 1)\n",
      "('email', 1)\n",
      "('pantry', 1)\n",
      "('\\xc2\\xbb', 1)\n",
      "('policiesamazon', 1)\n",
      "('diligently', 1)\n",
      "('irish', 1)\n",
      "('ad', 1)\n",
      "('contributors', 1)\n",
      "('dismay', 1)\n",
      "('ease', 1)\n",
      "('hosted', 1)\n",
      "('moved', 1)\n",
      "('shoulders', 1)\n",
      "('wildabouts', 1)\n",
      "('scientific', 1)\n",
      "('replica', 1)\n",
      "('kingdom', 1)\n",
      "('departments', 1)\n",
      "('amazonfresh', 1)\n",
      "('advertisers', 1)\n",
      "('repositories', 1)\n",
      "('check', 1)\n",
      "('visa', 1)\n",
      "('again', 1)\n",
      "('gay', 1)\n",
      "('deserve', 1)\n",
      "('deconstructed', 1)\n",
      "('alerts', 1)\n",
      "('graduate', 1)\n",
      "('members', 1)\n",
      "('tight', 1)\n",
      "('build', 1)\n",
      "('other', 1)\n",
      "('actors', 1)\n",
      "('genome', 1)\n",
      "('spectacle', 1)\n",
      "('really', 1)\n",
      "('outdoors', 1)\n",
      "('optimized', 1)\n",
      "('picture', 1)\n",
      "('championship', 1)\n",
      "('star', 1)\n",
      "('quilting', 1)\n",
      "('monday', 1)\n",
      "('hughes\\xe2\\x80\\x99s', 1)\n",
      "('prosecution', 1)\n",
      "('wars', 1)\n",
      "('william', 1)\n",
      "('across', 1)\n",
      "('coverage', 1)\n",
      "('included', 1)\n",
      "('friends', 1)\n",
      "('hl23', 1)\n",
      "('structure', 1)\n",
      "('billion', 1)\n",
      "('miles', 1)\n",
      "('australiabrazilcanadachinafrancegermanyindiaitalyjapanmexiconetherlandsspainunited', 1)\n",
      "('assets', 1)\n",
      "('phone', 1)\n",
      "('assume', 1)\n",
      "('restores', 1)\n",
      "('blogs', 1)\n",
      "('unlocked', 1)\n",
      "('love\\xe2\\x80\\x99', 1)\n",
      "('fifa\\xe2\\x80\\x99s', 1)\n",
      "('tenmarkscom', 1)\n",
      "('nelson', 1)\n",
      "('apparel', 1)\n",
      "('management', 1)\n",
      "('ordersshipping', 1)\n",
      "('hello', 1)\n",
      "('160160160women', 1)\n"
     ]
    }
   ],
   "source": [
    "class OrderedWebWordsFrequency(WebWordsFrequency):\n",
    "    \n",
    "    cur_pos = 0\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.urls = []\n",
    "        for arg in args:\n",
    "            self.urls.append(arg)\n",
    "        self.getWordsFrequency()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        if self.cur_pos >= len(self.l):\n",
    "            self.cur_pos = 0\n",
    "            raise StopIteration\n",
    "        res = self.l[self.cur_pos]\n",
    "        self.cur_pos += 1\n",
    "        return res\n",
    "        \n",
    "    def getWordsFrequency(self, **kwargs):\n",
    "        sum_dict = {}\n",
    "        for url in self.urls:\n",
    "            d = self.count_pure_word(url)\n",
    "            for key in d.keys():\n",
    "                if sum_dict.has_key(key):\n",
    "                    sum_dict[key] += d[key]\n",
    "                else:\n",
    "                    sum_dict[key] = d[key]\n",
    "        self.l = sum_dict.items()\n",
    "        if \"reverse\" not in kwargs:\n",
    "            kwargs[\"reverse\"] = False\n",
    "        if kwargs[\"reverse\"] == False:\n",
    "            self.l.sort(cmp = lambda a,b : cmp(b[1], a[1]))\n",
    "        else:\n",
    "            self.l.sort(cmp = lambda a,b : cmp(a[1], b[1]))\n",
    "        return self.l\n",
    "\n",
    "w4 = OrderedWebWordsFrequency('http://www.times.com', 'https://www.amazon.com', 'https://github.com')\n",
    "\n",
    "for i in w4:\n",
    "    print i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
